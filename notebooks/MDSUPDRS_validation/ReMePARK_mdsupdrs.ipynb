{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReMePARK ‚Äî An√°lisis Longitudinal de MDS-UPDRS\n",
    "\n",
    "Laboratorio Cl√≠nico de Enfermedades Neurodegenerativas (LCEN)  \n",
    "Instituto Nacional de Neurolog√≠a y Neurocirug√≠a ‚ÄúManuel Velasco Su√°rez‚Äù (INNN)  \n",
    "Ciudad de M√©xico, M√©xico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripci√≥n General\n",
    "\n",
    "Este cuaderno analiza datos longitudinales de la escala **MDS-UPDRS** (Movement Disorder Society ‚Äî Unified Parkinson‚Äôs Disease Rating Scale) de la cohorte **ReMePARK**.  \n",
    "El objetivo es visualizar trayectorias individuales, estimar cambios a lo largo del tiempo y explorar asociaciones con variables cl√≠nicas y terap√©uticas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos del An√°lisis\n",
    "\n",
    "1. Calcular el puntaje total de la MDS-UPDRS a partir de las subescalas I‚ÄìIV.  \n",
    "2. Describir la evoluci√≥n temporal del puntaje total y de cada subescala.  \n",
    "3. Comparar trayectorias entre grupos (por ejemplo, estado ON/OFF o cohorte intervenci√≥n/control).  \n",
    "4. Modelar el cambio longitudinal mediante regresiones lineales o modelos mixtos simples.  \n",
    "5. Generar visualizaciones reproducibles para informes y publicaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencias y entorno\n",
    "\n",
    "Requiere Python ‚â• 3.9 y los siguientes paquetes:\n",
    "\n",
    "- `pandas`, `numpy`\n",
    "- `matplotlib`, `seaborn`\n",
    "- `statsmodels` (para an√°lisis estad√≠stico)\n",
    "\n",
    "Instalaci√≥n r√°pida:\n",
    "```bash\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daljFitktGnN"
   },
   "source": [
    "| Art√≠culo                                                                                                   | Objetivo y muestra                                               | M√©todos clave                                                         | Hallazgos principales                                                                                                                                                                            | Relevancia pr√°ctica                                                                                                       |\n",
    "| ---------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- | --------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------- |\n",
    "| *Progression of MDS-UPDRS Scores Over Five Years in De Novo Parkinson Disease*                             | 362 pacientes PPMI sin tratamiento al inicio; seguimiento 5 a√±os | Modelos lineales mixtos (OFF)                                         | Progresi√≥n media anual: Total + 4.7; Parte I + 0.92; Parte II + 0.99; Parte III + 2.4 puntos                                                                                                     | Sirve de referencia para comparar eficacia de terapias modificadoras y para asesorar a pacientes reci√©n diagnosticados.   |\n",
    "| *Modeling of PD Progression and Implications for Detection of Disease Modification in Treatment Trials*    | Datos PPMI; validaci√≥n con placebo de PASADENA                   | Modelizaci√≥n no lineal de efectos mixtos + simulaciones de ensayos    | Parte III progresa ‚âà3 pt/a√±o, tres veces m√°s r√°pido que Parte II/I (‚âà1 pt/a√±o). Un efecto DMT medible en Parte III puede detectarse en ‚â§2 a√±os; Parte II requiere ‚â•3‚Äì5 a√±os.                     | Ofrece una herramienta para dimensionar ensayos y seleccionar el sub-score m√°s sensible seg√∫n la duraci√≥n.                |\n",
    "| *Estimation of and Clinical Consensus on the Meaningful Motor Progression Threshold on MDS-UPDRS Part III* | An√°lisis ancla-basado (PASADENA) + panel Delphi (13 expertos)    | Comparaci√≥n con CGI-I y consenso iterativo                            | Cambio de +5 puntos en Parte III (OFF) marca progresi√≥n motora cl√≠nicamente significativa.                                                                                                       | Establece un umbral √∫nico para eventos de progresi√≥n y desenlaces ‚Äútime-to-event‚Äù en ensayos precoces.                    |\n",
    "| *Handling Missing Values in the MDS-UPDRS*                                                                 | 842 pacientes (validaci√≥n) + cohorte internacional               | Eliminaci√≥n secuencial de √≠tems; prorrateo; concordancia de Lin ‚â•0.95 | Se permite: Parte I ‚â§1 √≠tem, Parte II ‚â§2 (aleatorios) o 1 (fijos), Parte III ‚â§7 (aleatorios) o 3 (fijos), Parte IV ning√∫n √≠tem; por encima, descartar o imputar con m√©todos m√°s robustos.        | Proporciona reglas operativas para limpiar bases de datos o aplicar telemedicina sin comprometer la validez del puntaje.  |\n",
    "| *MCID para MDS-UPDRS Partes I y II*                                                                        | 365 pacientes, 985 visitas; PGI-I como ancla                     | Tres t√©cnicas convergentes (regresi√≥n ordinal, ROC, medias)           | L√≠mite de importancia m√≠nima cl√≠nica (IMC): Parte I ¬±2.5‚Äì2.6 pts (mejor√≠a/empeoramiento); Parte II ¬±3.0‚Äì2.5 pts; Combinado I+II ¬±5.7‚Äì4.7 pts.                                                    | Permite interpretar cambios percibidos por el paciente en actividades de la vida diaria y planificar tama√±os muestrales.  |\n",
    "| *MCID para MDS-UPDRS Parte III*                                                                            | 260 pacientes, 728 visitas; CGI-I como ancla                     | M√©todos ancla y distribuci√≥n                                          | IMC asim√©trica: ‚àí3.25 pts (mejor√≠a m√≠nima), +4.63 pts (empeoramiento m√≠nimo) en Parte III.                                                                                                       | √ötil para decidir significaci√≥n cl√≠nica de cambios motores en pr√°ctica y ensayos.                                         |\n",
    "| *Systematic Review of MCID Thresholds in Movement Disorders*                                               | 32 estudios (11 sobre UPDRS/MDS-UPDRS)                           | Revisi√≥n PRISMA + evaluaci√≥n de sesgo                                 | Confirma rangos: Parte I ¬±2.5 pts; Parte II ¬±3 pts; Parte III ‚àí3 a ‚àí5 pts (mejor√≠a), +4‚Äì5 pts (empeoramiento); Parte IV ¬±0.9 pts. Resalta variabilidad metodol√≥gica y necesidad de estandarizar. | Ofrece marco comparativo y resalta la importancia de reportar MCID junto a significaci√≥n estad√≠stica.                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUCfn-HEtOnS"
   },
   "source": [
    "| Parte MDS-UPDRS                 | Leve ‚Üî Moderada | Moderada ‚Üî Grave |\n",
    "| ------------------------------- | --------------- | ---------------- |\n",
    "| **I** (no-motor EDV)            | **10/11**       | **21/22**        |\n",
    "| **II** (motor EDV)              | **12/13**       | **29/30**        |\n",
    "| **III** (exploraci√≥n)           | **32/33**       | **58/59**        |\n",
    "| **IV** (complicaciones motoras) | **4/5**         | **12/13**        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6xp4X1Dixym"
   },
   "source": [
    "## üîó Montar Google Drive\n",
    "\n",
    "Para acceder a los archivos del proyecto almacenados en **Google Drive**, monta tu unidad de forma segura.  \n",
    "Esto permite leer y guardar datos directamente desde tu repositorio de Drive sin descargarlos manualmente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIXYDhM_iPxA"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2sSnx5Ki6NL"
   },
   "source": [
    "## üß© Importar todas las librer√≠as\n",
    "\n",
    "En esta secci√≥n se importan todas las librer√≠as necesarias para el procesamiento, an√°lisis y visualizaci√≥n de los datos del proyecto **ReMePARK ‚Äì MDS-UPDRS*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwRhRoI1i6V-"
   },
   "outputs": [],
   "source": [
    "# Manejo de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fechas y tiempo\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Manejo de archivos y rutas\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Configuraci√≥n general de las gr√°ficas\n",
    "sns.set(style='whitegrid', context='notebook', font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llyYmkDwjKUl"
   },
   "source": [
    "\n",
    "### 5. **Carga de datos**\n",
    "```markdown\n",
    "## Carga y estructura de los datos\n",
    "\n",
    "El archivo de entrada debe colocarse en la carpeta `data/` (no incluido en el repositorio por motivos de privacidad).\n",
    "\n",
    "### Formato esperado (`rempark_mdsupdrs_long.csv`)\n",
    "| Columna | Tipo | Descripci√≥n |\n",
    "|----------|------|-------------|\n",
    "| `SubjectID` | str/int | Identificador del participante |\n",
    "| `Visit` | str/int | N√∫mero o etiqueta de visita |\n",
    "| `VisitDate` | date | Fecha de la visita |\n",
    "| `MDS_UPDRS_I` | float | No-motor experiences of daily living |\n",
    "| `MDS_UPDRS_II` | float | Motor experiences of daily living |\n",
    "| `MDS_UPDRS_III` | float | Exploraci√≥n motora |\n",
    "| `MDS_UPDRS_IV` | float | Complicaciones motoras |\n",
    "| `LEDD` | float (opcional) | Dosis equivalente de levodopa |\n",
    "| `State` | str (opcional) | Estado ON/OFF |\n",
    "| `Group` | str (opcional) | Cohorte o intervenci√≥n |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkowcaEHjKdt"
   },
   "outputs": [],
   "source": [
    "# Definir ruta\n",
    "file_path = '/content/drive/MyDrive/LCEN/08_Bases de Datos y Herramientas/08.1_ReMePARK/08.1.6_Unified ReMePARK 2024/Remepark_MDS-UPDRS.xlsx'\n",
    "\n",
    "# Cargar archivo Excel\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Ver las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMPVuYugkmOE"
   },
   "source": [
    "## üíæ Convertir a CSV\n",
    "\n",
    "Una vez que los datos han sido limpiados o combinados, se pueden exportar a formato **CSV** para conservar una versi√≥n procesada o facilitar su an√°lisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZ1YDBl3kmed"
   },
   "outputs": [],
   "source": [
    "# Definir nombre y ruta del archivo de salida\n",
    "csv_path = '/content/drive/MyDrive/LCEN/08_Bases de Datos y Herramientas/08.1_ReMePARK/08.1.6_Unified ReMePARK 2024/Remepark_mdsupdrs.csv'\n",
    "\n",
    "# Exportar DataFrame a CSV\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Archivo guardado correctamente en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_S1R4ssPkuEN"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8WMRn3Ak92K"
   },
   "source": [
    "## üßÆ Inicializar el marco de resultados de validaci√≥n\n",
    "\n",
    "Antes de comenzar la validaci√≥n de los c√°lculos o comparaciones entre columnas, es √∫til crear un **marco de resultados** (DataFrame) que almacene los indicadores de validaci√≥n para cada fila o sujeto.  \n",
    "\n",
    "Esto facilita centralizar los resultados de verificaci√≥n, m√©tricas o discrepancias detectadas en los c√°lculos del MDS-UPDRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXxPPfuDk9_A"
   },
   "outputs": [],
   "source": [
    "# Crear marco de resultados vac√≠o\n",
    "validation_results_updrs = pd.DataFrame()\n",
    "\n",
    "# Copiar identificadores desde el DataFrame original\n",
    "validation_results_updrs[\"fila_id\"] = df[\"fila_id\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju1PrECQoIsW"
   },
   "source": [
    "## ‚úÖ Validaci√≥n `num.consec`\n",
    "\n",
    "Esta secci√≥n verifica la **integridad y consistencia** de la columna `num.consec`, la cual representa un identificador o n√∫mero consecutivo √∫nico para cada registro.  \n",
    "Las validaciones comprueban tres aspectos fundamentales:\n",
    "\n",
    "1. **No nulos** ‚Üí garantiza que todos los registros tengan valor.  \n",
    "2. **Tipo num√©rico** ‚Üí asegura que los valores sean enteros o flotantes.  \n",
    "3. **Unicidad** ‚Üí valida que no existan duplicados en esta columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9OiRmOjtUBR"
   },
   "outputs": [],
   "source": [
    "# Validaciones para num.consec\n",
    "validation_results_updrs[\"num.consec.notnull\"] = df[\"num.consec\"].notnull()\n",
    "validation_results_updrs[\"num.consec.int\"] = df[\"num.consec\"].apply(lambda x: isinstance(x, (int, float)) and float(x).is_integer())\n",
    "validation_results_updrs[\"num.consec.unique\"] = ~df.duplicated(subset=[\"num.consec\"], keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDZcWWBEpt-G"
   },
   "outputs": [],
   "source": [
    "(validation_results_updrs[[\"num.consec.notnull\", \"num.consec.int\", \"num.consec.unique\"]] == False).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aePZyKkHpxQG"
   },
   "outputs": [],
   "source": [
    "# Mostrar filas que fallan al menos una validaci√≥n de num.consec\n",
    "errores_num_consec = ~validation_results_updrs[[\"num.consec.notnull\", \"num.consec.int\", \"num.consec.unique\"]].all(axis=1)\n",
    "\n",
    "# Mostrar datos originales correspondientes\n",
    "df[errores_num_consec]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Validaci√≥n de variables cl√≠nicas ‚Äî Subescalas MDS-UPDRS\n",
    "\n",
    "En esta secci√≥n se validan las **subescalas cl√≠nicas** de la MDS-UPDRS (Partes I a IV) para garantizar la calidad y consistencia de los datos antes del an√°lisis estad√≠stico.\n",
    "\n",
    "Las verificaciones contemplan:\n",
    "\n",
    "1. **Presencia de datos** (`notnull`)  \n",
    "2. **Tipo num√©rico v√°lido** (`isinstance`)  \n",
    "3. **Valores dentro de los rangos esperados** (seg√∫n el dise√±o de la escala)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas:\n",
    "\n",
    "Cada parte de la MDS-UPDRS tiene un rango m√°ximo distinto, pero en esta validaci√≥n inicial se aplica un rango general (0‚Äì132) como filtro de integridad.\n",
    "\n",
    "Si se desea una validaci√≥n m√°s espec√≠fica, se pueden ajustar los l√≠mites:\n",
    "\n",
    "Parte I: 0‚Äì52\n",
    "\n",
    "Parte II: 0‚Äì52\n",
    "\n",
    "Parte III: 0‚Äì132\n",
    "\n",
    "Parte IV: 0‚Äì24\n",
    "\n",
    "Los resultados (True/False) se almacenan por fila, permitiendo identificar r√°pidamente registros problem√°ticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gRSqib979ge"
   },
   "source": [
    "## üß© Identificar columnas por parte del MDS-UPDRS\n",
    "\n",
    "Antes de realizar validaciones o c√°lculos, es necesario **identificar las columnas** correspondientes a cada una de las partes de la escala **MDS-UPDRS (I, II, III, IV)**.  \n",
    "Esto facilita aplicar operaciones agrupadas (por ejemplo, sumas o validaciones de rango) sin escribir manualmente cada nombre de √≠tem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas:\n",
    "\n",
    "Cada lista contiene las columnas correspondientes a los √≠tems de cada parte.\n",
    "\n",
    "El prefijo (\"UPDRS1.\", \"UPDRS2.\", etc.) debe coincidir exactamente con los nombres de tus columnas.\n",
    "\n",
    "Este enfoque automatiza la selecci√≥n, √∫til cuando se trabaja con bases de datos extensas o exportadas desde REDCap, Excel o SPSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfLzrgiM79qU"
   },
   "outputs": [],
   "source": [
    "updrs1_cols = [col for col in df.columns if col.startswith(\"UPDRS1.\")]\n",
    "updrs2_cols = [col for col in df.columns if col.startswith(\"UPDRS2.\")]\n",
    "updrs3_cols = [col for col in df.columns if col.startswith(\"UPDRS3.\")]\n",
    "updrs4_cols = [col for col in df.columns if col.startswith(\"UPDRS4.\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rHQltZy8H7p"
   },
   "source": [
    "## ‚úÖ Validaci√≥n de columnas con valores num√©ricos\n",
    "\n",
    "Una vez identificadas las columnas, se valida que **todas las celdas contengan valores num√©ricos v√°lidos** en cada parte de la MDS-UPDRS.  \n",
    "Esto previene errores en los c√°lculos de sumas o promedios en etapas posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas:\n",
    "\n",
    "pd.to_numeric(..., errors=\"coerce\") convierte valores no num√©ricos en NaN, evitando que se rompan las operaciones aritm√©ticas.\n",
    "\n",
    "Es recomendable verificar despu√©s el n√∫mero de NaN generados para detectar errores de carga o formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPmuWIJ78IKo"
   },
   "outputs": [],
   "source": [
    "df[updrs1_cols + updrs2_cols + updrs3_cols + updrs4_cols] = df[updrs1_cols + updrs2_cols + updrs3_cols + updrs4_cols].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DojPkHFx5Hyb"
   },
   "source": [
    "## üìö Agrupar y validar MDS-UPDRS por partes (I‚ÄìIV)\n",
    "\n",
    "En esta secci√≥n se:\n",
    "1) **Identifican** las columnas de cada parte de la MDS-UPDRS.  \n",
    "2) **Convierten** a num√©rico con coerci√≥n (valores inv√°lidos ‚Üí `NaN`).  \n",
    "3) **Validan rangos por fila** (√≠tems con valores entre 0 y 4).  \n",
    "4) **Filtran** filas v√°lidas por parte para evitar sesgos en sumas y promedios.\n",
    "\n",
    "> **Regla de validaci√≥n:** cada fila es v√°lida si **todos** los √≠tems no nulos de esa parte est√°n en \\[0, 1, 2, 3, 4\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas\n",
    "- **Conversi√≥n a num√©rico:** asegura que valores como `\"3 \"` o `\"2.0\"` no provoquen errores (se convierten a `float`).  \n",
    "- **Validaci√≥n 0‚Äì4:** sigue la escala de cada √≠tem MDS-UPDRS (0 = normal; 4 = severo).  \n",
    "- **Filtrado incremental:** se filtra por parte de forma secuencial para conservar observaciones con datos v√°lidos en todas las partes consideradas.  \n",
    "- **Suma por parte:** usa `min_count=1` para evitar que filas con todos `NaN` devuelvan 0 de forma enga√±osa.  \n",
    "- **Ajusta las listas de columnas** si tus nombres no coinciden exactamente con los ejemplos (`UPDRS1.x`, `UPDRS2.x`, etc.).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVrexUna6IR_"
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# MDS-UPDRS Part 1Ô∏è‚É£\n",
    "# ===============================\n",
    "updrs1_cols = [f\"UPDRS1.{i}\" for i in range(1, 14)]  # UPDRS1.1 to UPDRS1.13\n",
    "\n",
    "df_updrs1 = df.copy()\n",
    "df_updrs1[updrs1_cols] = df_updrs1[updrs1_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "df_updrs1_filtered = df_updrs1[df_updrs1[updrs1_cols].apply(\n",
    "    lambda row: row.dropna().isin([0, 1, 2, 3, 4]).all(), axis=1\n",
    ")]\n",
    "\n",
    "# ===============================\n",
    "# MDS-UPDRS Part 2Ô∏è‚É£\n",
    "# ===============================\n",
    "updrs2_cols = [f\"UPDRS2.{i}\" for i in range(1, 14)]  # UPDRS2.1 to UPDRS2.13\n",
    "\n",
    "df_updrs2 = df_updrs1_filtered.copy()\n",
    "df_updrs2[updrs2_cols] = df_updrs2[updrs2_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "df_updrs2_filtered = df_updrs2[df_updrs2[updrs2_cols].apply(\n",
    "    lambda row: row.dropna().isin([0, 1, 2, 3, 4]).all(), axis=1\n",
    ")]\n",
    "\n",
    "# ===============================\n",
    "# MDS-UPDRS Part 3Ô∏è‚É£\n",
    "# ===============================\n",
    "updrs3_cols = [\n",
    "    \"UPDRS3.1\", \"UPDRS3.2\", \"UPDRS3.3C\", \"UPDRS3.3MSD\", \"UPDRS3.3MSI\", \"UPDRS3.3MID\", \"UPDRS3.3MII\",\n",
    "    \"UPDRS3.4MD\", \"UPDRS3.4MI\", \"UPDRS3.5MD\", \"UPDRS3.5MI\", \"UPDRS3.6MD\", \"UPDRS3.6MI\",\n",
    "    \"UPDRS3.7PD\", \"UPDRS3.7PI\", \"UPDRS3.8PD\", \"UPDRS3.8PI\", \"UPDRS3.9\", \"UPDRS3.10\",\n",
    "    \"UPDRS3.11\", \"UPDRS3.12\", \"UPDRS3.13\", \"UPDRS3.14\", \"UPDRS3.15MD\", \"UPDRS3.15MI\",\n",
    "    \"UPDRS3.16MD\", \"UPDRS3.16MI\", \"UPDRS3.17MSD\", \"UPDRS3.17MSI\", \"UPDRS3.17MID\",\n",
    "    \"UPDRS3.17MII\", \"UPDRS3.17LM\", \"UPDRS3.18\"\n",
    "]\n",
    "\n",
    "df_updrs3 = df_updrs2_filtered.copy()\n",
    "df_updrs3[updrs3_cols] = df_updrs3[updrs3_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "df_updrs3_filtered = df_updrs3[df_updrs3[updrs3_cols].apply(\n",
    "    lambda row: row.dropna().isin([0, 1, 2, 3, 4]).all(), axis=1\n",
    ")]\n",
    "\n",
    "# ===============================\n",
    "# MDS-UPDRS Part 4Ô∏è‚É£\n",
    "# ===============================\n",
    "updrs4_cols = [f\"UPDRS4.{i}\" for i in range(1, 7)]  # UPDRS4.1 to UPDRS4.6\n",
    "\n",
    "df_updrs4 = df_updrs3_filtered.copy()\n",
    "df_updrs4[updrs4_cols] = df_updrs4[updrs4_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "df_updrs4_filtered = df_updrs4[df_updrs4[updrs4_cols].apply(\n",
    "    lambda row: row.dropna().isin([0, 1, 2, 3, 4]).all(), axis=1\n",
    ")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXU46Q-I6QiT"
   },
   "source": [
    "## Calcular las puntuaciones totales de cada parte\n",
    "\n",
    "Se suma por fila cada conjunto de √≠tems pertenecientes a la parte I‚ÄìIV.  \n",
    "`skipna=True` evita que valores faltantes rompan la suma; `min_count=1` impide que una fila con todos `NaN` devuelva 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aseg√∫rate de que updrs1_cols, updrs2_cols, updrs3_cols y updrs4_cols contengan √∫nicamente los √≠tems v√°lidos de cada parte.\n",
    "\n",
    "Si decides imputar valores faltantes antes de sumar, hazlo expl√≠cito (por ejemplo, fillna(0)), y documenta la decisi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klOGSFEe8bqA"
   },
   "outputs": [],
   "source": [
    "df[\"UPDRS1.TOTAL\"] = df[updrs1_cols].sum(axis=1, skipna=True)\n",
    "df[\"UPDRS2.TOTAL\"] = df[updrs2_cols].sum(axis=1, skipna=True)\n",
    "df[\"UPDRS3.TOTAL\"] = df[updrs3_cols].sum(axis=1, skipna=True)\n",
    "df[\"UPDRS4.TOTAL\"] = df[updrs4_cols].sum(axis=1, skipna=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuEPJSAp8esy"
   },
   "source": [
    "## Calcular la puntuaci√≥n total MDS-UPDRS\n",
    "\n",
    "La puntuaci√≥n total se obtiene como la suma de las partes I‚ÄìIV.  \n",
    "Se recomienda usar `min_count=1` en cada parcial (como arriba) para que la suma total refleje correctamente filas con datos faltantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tu base no incluye la parte IV, ajusta la suma en consecuencia.\n",
    "\n",
    "Verifica rangos esperados post-suma para detectar valores at√≠picos por carga/transformaci√≥n err√≥nea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jceEyadx8e39"
   },
   "outputs": [],
   "source": [
    "df[\"UPDRS.TOTAL\"] = (\n",
    "    df[\"UPDRS1.TOTAL\"] +\n",
    "    df[\"UPDRS2.TOTAL\"] +\n",
    "    df[\"UPDRS3.TOTAL\"] +\n",
    "    df[\"UPDRS4.TOTAL\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "752Kma0F8qHl"
   },
   "outputs": [],
   "source": [
    "print(df[[\"UPDRS1.TOTAL\", \"UPDRS2.TOTAL\", \"UPDRS3.TOTAL\", \"UPDRS4.TOTAL\", \"UPDRS.TOTAL\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02ONmcwqofhm"
   },
   "source": [
    "## ‚öôÔ∏è Reglas de integridad y prorrateo\n",
    "\n",
    "**Referencia:**  \n",
    "Goetz CG, Luo S, Wang L, Tilley BC, LaPelle NR, Stebbins GT. *Handling missing values in the MDS-UPDRS.*  \n",
    "Mov Disord. 2015 Oct;30(12):1632-8. doi: [10.1002/mds.26153](https://doi.org/10.1002/mds.26153).  \n",
    "PMID: 25649812; PMCID: PMC5072275.\n",
    "\n",
    "---\n",
    "\n",
    "### üßæ Criterios\n",
    "\n",
    "Seg√∫n Goetz et al. (2015), se permite el c√°lculo prorrateado de la MDS-UPDRS **si no se supera el umbral m√°ximo de √≠tems faltantes** por parte:\n",
    "\n",
    "| Parte | Umbral m√°ximo de √≠tems faltantes | Comentario |\n",
    "|:------|:--------------------------------:|:------------|\n",
    "| I     | ‚â§ 1 √≠tem                         | Aceptable |\n",
    "| II    | ‚â§ 2 √≠tems (aleatorios) o 1 (fijo) | |\n",
    "| III   | ‚â§ 7 √≠tems (aleatorios) o 3 (fijos) | |\n",
    "| IV    | 0 √≠tems                           | Ninguno permitido |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHfEpO4IqBvx"
   },
   "source": [
    "*Se permite: Parte I ‚â§1 √≠tem, Parte II ‚â§2 (aleatorios) o 1 (fijos), Parte III ‚â§7 (aleatorios) o 3 (fijos), Parte IV ning√∫n √≠tem; por encima, descartar o imputar con m√©todos m√°s robustos.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwgnNPUBof3C"
   },
   "outputs": [],
   "source": [
    "# --- 1.1 Umbrales m√°ximos de √≠tems faltantes (Goetz 2015)\n",
    "MISSING_RULES = {\"I\": 1, \"II\": 2, \"III\": 7, \"IV\": 0}\n",
    "\n",
    "# --- 1.2 Diccionario de √≠tems por parte (ya los definiste antes)\n",
    "parte_items = {\n",
    "    \"I\": updrs1_cols,\n",
    "    \"II\": updrs2_cols,\n",
    "    \"III\": updrs3_cols,\n",
    "    \"IV\": updrs4_cols,\n",
    "}\n",
    "\n",
    "# --- 1.3 Funciones utilitarias\n",
    "def es_valido_fila(row, parte):\n",
    "    max_missing = MISSING_RULES[parte]\n",
    "    n_missing = row[parte_items[parte]].isna().sum()\n",
    "    return n_missing <= max_missing\n",
    "\n",
    "def prorratear_fila(row, parte):\n",
    "    items = parte_items[parte]\n",
    "    miss = row[items].isna()\n",
    "    if miss.any():\n",
    "        factor = len(items) / (~miss).sum()\n",
    "        row[items] = row[items].fillna(0) * factor\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SI3D8mVqqLbq"
   },
   "source": [
    "## üßÆ C√°lculo de totales con prorrateo (sin descartar filas)\n",
    "\n",
    "Este bloque ejecuta las funciones anteriores para:\n",
    "1. Validar el umbral de faltantes por parte.  \n",
    "2. Aplicar prorrateo cuando corresponde.  \n",
    "3. Calcular los totales por parte y el puntaje global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas:\n",
    "\n",
    "Este procedimiento no descarta filas, pero s√≥lo aplica el prorrateo cuando el n√∫mero de √≠tems faltantes est√° dentro del umbral permitido.\n",
    "\n",
    "Los totales se recalculan despu√©s de imputar los valores proporcionalmente.\n",
    "\n",
    "El resultado df_clean conserva la misma estructura del DataFrame original con nuevas columnas:\n",
    "\n",
    "MDS_UPDRS_I, MDS_UPDRS_II, MDS_UPDRS_III, MDS_UPDRS_IV\n",
    "\n",
    "MDS_UPDRS_TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8TzH5bXqM79"
   },
   "outputs": [],
   "source": [
    "def calcular_totales_con_prorrateo(df):\n",
    "    df_out = df.copy()\n",
    "    for parte in [\"I\", \"II\", \"III\", \"IV\"]:\n",
    "        # 2.1 Validar umbral de missing\n",
    "        df_out = df_out[df_out.apply(es_valido_fila, axis=1, args=(parte,))]\n",
    "        # 2.2 Prorratear si procede\n",
    "        df_out = df_out.apply(prorratear_fila, axis=1, args=(parte,))\n",
    "        # 2.3 Sumar puntaje\n",
    "        df_out[f\"MDS_UPDRS_{parte}\"] = df_out[parte_items[parte]].sum(axis=1)\n",
    "    # 2.4 Puntaje total\n",
    "    df_out[\"MDS_UPDRS_TOTAL\"] = df_out[[f\"MDS_UPDRS_{p}\" for p in \"I II III IV\".split()]].sum(axis=1)\n",
    "    return df_out\n",
    "\n",
    "# === Ejecuta ===\n",
    "df_clean = calcular_totales_con_prorrateo(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agUqxqf7ELgN"
   },
   "source": [
    "## üß© MDS-UPDRS Parte I\n",
    "\n",
    "Esta secci√≥n valida los √≠tems correspondientes a la **Parte I** de la escala MDS-UPDRS (*Experiencias no motoras de la vida diaria*).  \n",
    "El objetivo es garantizar que los datos sean num√©ricos, est√©n dentro del rango permitido (0‚Äì4) y que cada registro contenga el n√∫mero esperado de √≠tems v√°lidos (13 para esta parte).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXLtrsGi9SDi"
   },
   "source": [
    "### C√≥digo para validar MDS-UPDRS Parte I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas\n",
    "\n",
    "Cada √≠tem de la Parte I debe tener un valor de 0 a 4 (0 = normal, 4 = muy severo).\n",
    "\n",
    "Si alguna celda tiene valores fuera de rango o vac√≠os, se marca como no v√°lida.\n",
    "\n",
    "La columna UPDRS1.completo confirma que la fila contiene los 13 √≠tems v√°lidos esperados.\n",
    "\n",
    "UPDRS1.con_errores = True indica que la observaci√≥n no cumple con los criterios m√≠nimos de integridad.\n",
    "\n",
    "Este mismo procedimiento puede adaptarse f√°cilmente a las Partes II‚ÄìIV modificando el prefijo (UPDRS2., UPDRS3., etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjzW6aOu9SNg"
   },
   "outputs": [],
   "source": [
    "# Identificar columnas de Parte I\n",
    "updrs1_cols = [col for col in df.columns if col.startswith(\"UPDRS1.\")]\n",
    "updrs1_cols = sorted(updrs1_cols)  # Ordenar por si est√°n desordenadas\n",
    "\n",
    "# Asegurar que las columnas sean num√©ricas\n",
    "df[updrs1_cols] = df[updrs1_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Validar valor individual entre 0 y 4\n",
    "for col in updrs1_cols:\n",
    "    validation_results_updrs[f\"{col}.valido\"] = df[col].isin([0, 1, 2, 3, 4])\n",
    "\n",
    "# Validar que haya exactamente 13 √≠tems v√°lidos\n",
    "validation_results_updrs[\"UPDRS1.completo\"] = df[updrs1_cols].apply(\n",
    "    lambda row: row.dropna().isin([0, 1, 2, 3, 4]).sum() == 13, axis=1\n",
    ")\n",
    "\n",
    "# Agregar columna de error general para la Parte I\n",
    "validation_results_updrs[\"UPDRS1.con_errores\"] = ~validation_results_updrs[\n",
    "    [f\"{col}.valido\" for col in updrs1_cols] + [\"UPDRS1.completo\"]\n",
    "].all(axis=1)\n",
    "\n",
    "# Mostrar filas con errores\n",
    "errores_updrs1 = validation_results_updrs[validation_results_updrs[\"UPDRS1.con_errores\"]]\n",
    "\n",
    "# Visualizar errores\n",
    "print(\"Errores detectados en UPDRS Parte I:\")\n",
    "display(errores_updrs1.head(10))  # O usa .to_excel si deseas exportar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I41xt5ENAkrl"
   },
   "source": [
    "## Porcentaje de valores faltantes por √≠tem ‚Äî MDS-UPDRS Parte I\n",
    "\n",
    "Este an√°lisis estima el porcentaje de celdas faltantes por √≠tem en la Parte I, √∫til para diagn√≥stico de calidad de datos y decisiones de imputaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_727LVQAlOR"
   },
   "outputs": [],
   "source": [
    "# Identificar columnas de la Parte I\n",
    "updrs1_cols = [col for col in df.columns if col.startswith(\"UPDRS1.\")]\n",
    "updrs1_cols = sorted(updrs1_cols)\n",
    "\n",
    "# Calcular porcentaje de missing por √≠tem\n",
    "missing_percent_updrs1 = df[updrs1_cols].isna().mean().round(3) * 100\n",
    "\n",
    "# Convertir a DataFrame para visualizar o exportar\n",
    "missing_percent_updrs1_df = missing_percent_updrs1.reset_index()\n",
    "missing_percent_updrs1_df.columns = [\"√çtem\", \"% Missing\"]\n",
    "\n",
    "# Mostrar\n",
    "print(missing_percent_updrs1_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-ArUjsKCHgp"
   },
   "source": [
    "## üß™ Test de Little ‚Äî MCAR (Missing Completely at Random)\n",
    "\n",
    "El **Test de Little MCAR** eval√∫a si los valores faltantes en los √≠tems ocurren de manera completamente aleatoria (*Missing Completely at Random*).  \n",
    "Esto permite decidir si es apropiado aplicar imputaci√≥n simple o si los datos presentan sesgos sistem√°ticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Interpretaci√≥n de resultados\n",
    "- Si **p-value < 0.05** ‚Üí Hay diferencia significativa ‚Üí **No MCAR** (faltantes no aleatorios).  \n",
    "- Si **p-value ‚â• 0.05** ‚Üí No hay diferencia significativa ‚Üí **Posiblemente MCAR** (faltantes aleatorios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0fjyDjGC7Pg"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "\n",
    "# Asegura que los √≠tems est√°n en formato num√©rico\n",
    "updrs1_cols = sorted([col for col in df.columns if col.startswith(\"UPDRS1.\") and col != \"UPDRS1.TOTAL\"])\n",
    "df[updrs1_cols] = df[updrs1_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Crear lista para resultados\n",
    "ttest_results = []\n",
    "\n",
    "# Comparar cada √≠tem con los dem√°s\n",
    "for target_col in updrs1_cols:\n",
    "    row_results = {\"item\": target_col}\n",
    "    for other_col in updrs1_cols:\n",
    "        if other_col != target_col:\n",
    "            group1 = df[df[other_col].isnull()][target_col].dropna()\n",
    "            group2 = df[df[other_col].notnull()][target_col].dropna()\n",
    "\n",
    "            # Asegurar tama√±o m√≠nimo para aplicar prueba t\n",
    "            if len(group1) >= 5 and len(group2) >= 5:\n",
    "                stat, p = ttest_ind(group1, group2, equal_var=False, nan_policy='omit')\n",
    "                row_results[f\"p_vs_{other_col}\"] = round(p, 4)\n",
    "            else:\n",
    "                row_results[f\"p_vs_{other_col}\"] = None\n",
    "    ttest_results.append(row_results)\n",
    "\n",
    "# Convertir a DataFrame y mostrar\n",
    "ttest_df = pd.DataFrame(ttest_results)\n",
    "ttest_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CX5GZpjRCkwo"
   },
   "source": [
    "## üßÆ Modelo predictivo del patr√≥n de *missing*\n",
    "\n",
    "Este modelo eval√∫a si los valores faltantes pueden **predecirse a partir de otras variables**.  \n",
    "Se basa en una regresi√≥n log√≠stica binaria para cada √≠tem, donde la variable dependiente es ‚Äúfaltante o no faltante‚Äù.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Interpretaci√≥n de resultados\n",
    "- **Pseudo R¬≤ bajo (< 0.05)** ‚Üí la variable objetivo (missing o no) **no se predice bien** ‚Üí evidencia de **MCAR** (faltantes completamente aleatorios).  \n",
    "- **Pseudo R¬≤ moderado o alto (> 0.10)** ‚Üí el patr√≥n de faltantes puede estar **relacionado con otras variables** ‚Üí indicio de **MAR** o **MNAR** (faltantes no completamente aleatorios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaoyqBDaDo7_"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "predictive_missing_results = []\n",
    "\n",
    "for target_col in updrs1_cols:\n",
    "    y = df[target_col].isnull().astype(int)  # variable objetivo: 1 si falta, 0 si no\n",
    "    predictors = [col for col in updrs1_cols if col != target_col and col != \"UPDRS1.VALIDO\"]\n",
    "\n",
    "    X = df[predictors].copy()\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    model_data = pd.concat([X, y], axis=1).dropna()\n",
    "\n",
    "    if model_data.shape[0] >= 30:\n",
    "        X_clean = model_data[predictors].astype(float)\n",
    "        y_clean = model_data[target_col].astype(float)\n",
    "\n",
    "        X_clean = sm.add_constant(X_clean)\n",
    "\n",
    "        try:\n",
    "            model = sm.Logit(y_clean, X_clean).fit(disp=0)\n",
    "            pseudo_r2 = model.prsquared\n",
    "            predictive_missing_results.append({\n",
    "                \"Item\": target_col,\n",
    "                \"Pseudo R¬≤\": round(pseudo_r2, 4),\n",
    "                \"n_obs\": model_data.shape[0]\n",
    "            })\n",
    "        except Exception as e:\n",
    "            predictive_missing_results.append({\n",
    "                \"Item\": target_col,\n",
    "                \"Pseudo R¬≤\": \"Error\",\n",
    "                \"n_obs\": model_data.shape[0],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "# Mostrar resultados\n",
    "predictive_df = pd.DataFrame(predictive_missing_results)\n",
    "display(predictive_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzYwcok3BKQ7"
   },
   "source": [
    "## Imputabilidad por √≠tem (criterios y reporte)\n",
    "\n",
    "Se eval√∫a, para cada √≠tem de la Parte I, si cumple criterios m√≠nimos para ser imputado:\n",
    "\n",
    "1) Es num√©rico.  \n",
    "2) Sus valores observados est√°n en el rango 0‚Äì4.  \n",
    "3) Porcentaje de valores faltantes por debajo de un umbral (por defecto, 20 %).\n",
    "\n",
    "El resultado es una tabla con el estado de imputabilidad por √≠tem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notas\n",
    "- Ajusta `umbral_missing` seg√∫n el plan anal√≠tico (por ejemplo, 10 %, 15 %, 20 %).  \n",
    "- Si `Num√©rico` es falso, convierte previamente con `pd.to_numeric(..., errors=\"coerce\")`.  \n",
    "- Revisa √≠tems con `% Missing` alto aunque sean imputables; podr√≠an requerir inspecci√≥n manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Gi7yU3rBKbX"
   },
   "outputs": [],
   "source": [
    "# Definir umbral de imputabilidad (porcentaje de missing aceptable)\n",
    "umbral_missing = 20\n",
    "\n",
    "# Revisar si cada √≠tem est√° en escala 0‚Äì4 y tiene % de missing < 20\n",
    "imputabilidad = []\n",
    "for col in updrs1_cols:\n",
    "    es_numerico = pd.api.types.is_numeric_dtype(df[col])\n",
    "    en_rango = df[col].dropna().isin([0, 1, 2, 3, 4]).all()\n",
    "    missing_pct = df[col].isna().mean() * 100\n",
    "    imputable = es_numerico and en_rango and (missing_pct < umbral_missing)\n",
    "    imputabilidad.append({\n",
    "        \"√çtem\": col,\n",
    "        \"Imputable\": imputable,\n",
    "        \"% Missing\": round(missing_pct, 2),\n",
    "        \"Num√©rico\": es_numerico,\n",
    "        \"Rango 0‚Äì4\": en_rango\n",
    "    })\n",
    "\n",
    "# Convertir a DataFrame y mostrar\n",
    "imputabilidad_df = pd.DataFrame(imputabilidad)\n",
    "print(imputabilidad_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLzfL5r_Bh-j"
   },
   "source": [
    "## ü§ñ Criterios y c√≥digo para sugerencia de m√©todo de imputaci√≥n\n",
    "\n",
    "Este bloque genera una **recomendaci√≥n autom√°tica del m√©todo de imputaci√≥n** m√°s adecuado para cada √≠tem seg√∫n su porcentaje de valores faltantes y el tipo de variable.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Criterios de decisi√≥n\n",
    "\n",
    "| % Missing | Tipo / Escala | M√©todo sugerido |\n",
    "|------------|----------------|-----------------|\n",
    "| > 30 %     | ‚Äî | **No imputar** (demasiada p√©rdida de informaci√≥n) |\n",
    "| < 5 %      | Ordinal (0‚Äì4) | **Moda** |\n",
    "| 5‚Äì20 %     | Ordinal (0‚Äì4) | **Mediana por grupo** o **Regresi√≥n ordinal** |\n",
    "| 20‚Äì30 %    | Ordinal (0‚Äì4) | **KNN Imputation** (para mantener estructura multivariada) |\n",
    "| ‚Äî          | Otros tipos | **Evaluar manualmente** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas\n",
    "\n",
    "La l√≥gica est√° pensada para √≠tems ordinales con escala 0‚Äì4, como los de la MDS-UPDRS.\n",
    "\n",
    "Para √≠tems continuos o binarios, puede adaptarse el bloque tipo dentro de la funci√≥n (\"continuo\", \"binario\").\n",
    "\n",
    "Si un √≠tem tiene >30 % de valores faltantes, no debe imputarse: lo recomendable es excluirlo o analizar causas de ausencia.\n",
    "\n",
    "Los m√©todos ‚ÄúMediana por grupo‚Äù o ‚ÄúRegresi√≥n ordinal‚Äù preservan la estructura ordinal del √≠tem y evitan sesgos sistem√°ticos.\n",
    "\n",
    "El m√©todo KNN puede ser √∫til cuando hay correlaci√≥n fuerte entre √≠tems de la misma parte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Io0OAG8dBiE5"
   },
   "outputs": [],
   "source": [
    "# Definir funci√≥n de recomendaci√≥n\n",
    "def sugerir_metodo_imputacion(missing_pct, tipo=\"ordinal\", escala=(0, 4)):\n",
    "    if missing_pct > 30:\n",
    "        return \"No imputar (>30% missing)\"\n",
    "    elif tipo == \"ordinal\" and escala == (0, 4):\n",
    "        if missing_pct < 5:\n",
    "            return \"Moda\"\n",
    "        elif missing_pct < 20:\n",
    "            return \"Mediana por grupo o regresi√≥n ordinal\"\n",
    "        else:\n",
    "            return \"KNN imputaci√≥n\"\n",
    "    else:\n",
    "        return \"Evaluar manualmente\"\n",
    "\n",
    "# Aplicar recomendaciones por √≠tem\n",
    "sugerencias = []\n",
    "for col in updrs1_cols:\n",
    "    pct_missing = df[col].isna().mean() * 100\n",
    "    metodo = sugerir_metodo_imputacion(pct_missing)\n",
    "    sugerencias.append({\"√çtem\": col, \"% Missing\": round(pct_missing, 2), \"M√©todo sugerido\": metodo})\n",
    "\n",
    "# Convertir a DataFrame y mostrar\n",
    "sugerencias_df = pd.DataFrame(sugerencias)\n",
    "print(sugerencias_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHimOzF8FNlQ"
   },
   "source": [
    "## üß© MDS-UPDRS Parte II\n",
    "\n",
    "Esta secci√≥n replica el proceso de validaci√≥n aplicado a la Parte I, ahora sobre la **Parte II** (*Experiencias motoras de la vida diaria*).  \n",
    "Se eval√∫a integridad, consistencia y completitud de los √≠tems correspondientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nawv75bGJxz"
   },
   "outputs": [],
   "source": [
    "# Identificar columnas de Parte II\n",
    "updrs2_cols = [col for col in df.columns if col.startswith(\"UPDRS2.\")]\n",
    "updrs2_cols = sorted(updrs2_cols)  # Ordenar por si est√°n desordenadas\n",
    "\n",
    "# Asegurar que las columnas sean num√©ricas\n",
    "df[updrs2_cols] = df[updrs2_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Validar valor individual entre 0 y 4\n",
    "for col in updrs2_cols:\n",
    "    validation_results_updrs[f\"{col}.valido\"] = df[col].isin([0, 1, 2, 3, 4])\n",
    "\n",
    "# Validar que haya exactamente 13 √≠tems v√°lidos\n",
    "validation_results_updrs[\"UPDRS2.completo\"] = df[updrs2_cols].apply(\n",
    "    lambda row: row.dropna().isin([0, 1, 2, 3, 4]).sum() == 13, axis=1\n",
    ")\n",
    "\n",
    "# Agregar columna de error general para la Parte II\n",
    "validation_results_updrs[\"UPDRS2.con_errores\"] = ~validation_results_updrs[\n",
    "    [f\"{col}.valido\" for col in updrs2_cols] + [\"UPDRS2.completo\"]\n",
    "].all(axis=1)\n",
    "\n",
    "# Mostrar filas con errores\n",
    "errores_updrs2 = validation_results_updrs[validation_results_updrs[\"UPDRS2.con_errores\"]]\n",
    "\n",
    "# Visualizar errores\n",
    "print(\"Errores detectados en UPDRS Parte II:\")\n",
    "display(errores_updrs2.head(10))  # O usa .to_excel si deseas exportar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUuabqSMG1Yd"
   },
   "source": [
    "## Porcentaje de valores faltantes por √≠tem ‚Äî MDS-UPDRS Parte II\n",
    "Eval√∫a el porcentaje de valores ausentes por cada √≠tem, detectando posibles √°reas problem√°ticas antes de imputaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrSh9nf_G1fY"
   },
   "outputs": [],
   "source": [
    "updrs2_cols = sorted([col for col in df.columns if col.startswith(\"UPDRS2.\")])\n",
    "missing_percent_updrs2 = df[updrs2_cols].isna().mean().round(3) * 100\n",
    "missing_percent_updrs2_df = missing_percent_updrs2.reset_index()\n",
    "missing_percent_updrs2_df.columns = [\"√çtem\", \"% Missing\"]\n",
    "print(\"Parte II:\")\n",
    "print(missing_percent_updrs2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEbdo9V2HT0_"
   },
   "source": [
    "## üß™ Test de Little ‚Äî MCAR (Parte II)\n",
    "Verifica si los valores faltantes en la Parte II ocurren de forma completamente aleatoria.  \n",
    "Si *p* ‚â• 0.05 ‚Üí posiblemente MCAR; si *p* < 0.05 ‚Üí evidencia de no MCAR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpCABggUHUwt"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "\n",
    "# Asegurar que todas las columnas relevantes est√©n en formato num√©rico\n",
    "def run_ttests_for_part(df, prefix):\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    ttest_results = []\n",
    "\n",
    "    for target_col in cols:\n",
    "        row_results = {\"item\": target_col}\n",
    "        for other_col in cols:\n",
    "            if other_col != target_col:\n",
    "                group1 = df[df[other_col].isnull()][target_col].dropna()\n",
    "                group2 = df[df[other_col].notnull()][target_col].dropna()\n",
    "\n",
    "                if len(group1) >= 5 and len(group2) >= 5:\n",
    "                    stat, p = ttest_ind(group1, group2, equal_var=False, nan_policy='omit')\n",
    "                    row_results[f\"p_vs_{other_col}\"] = round(p, 4)\n",
    "                else:\n",
    "                    row_results[f\"p_vs_{other_col}\"] = None\n",
    "        ttest_results.append(row_results)\n",
    "\n",
    "    return pd.DataFrame(ttest_results)\n",
    "\n",
    "# Aplicar a cada parte\n",
    "ttest_df_part2 = run_ttests_for_part(df, \"UPDRS2.\")\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"T-test resultados Parte II:\")\n",
    "display(ttest_df_part2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9zD6qRfIQ__"
   },
   "source": [
    "## üßÆ Modelo predictivo del patr√≥n de missing ‚Äî MDS-UPDRS Parte II\n",
    "Se utiliza regresi√≥n log√≠stica para estimar si la presencia de datos faltantes en un √≠tem puede predecirse por otros,  \n",
    "identificando patrones MAR/MNAR (dependencia estructurada entre variables).\n",
    "\n",
    "\n",
    "Interpretaci√≥n del output Pseudo R¬≤ bajo (< 0.05): la variable objetivo (missing o no) no se puede predecir bien ‚Üí evidencia de MCAR.\n",
    "\n",
    "Pseudo R¬≤ moderado/alto (> 0.1): el patr√≥n de missing puede estar relacionado con otras variables ‚Üí MAR o MNAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mlg6UxNgIRJJ"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "def run_predictive_missingness(df, prefix):\n",
    "    # Identificar columnas que comienzan con el prefijo y no son totales\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "\n",
    "    # Asegurar que sean num√©ricos\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for target_col in cols:\n",
    "        y = df[target_col].isnull().astype(int)\n",
    "        predictors = [col for col in cols if col != target_col]\n",
    "\n",
    "        X = df[predictors].copy()\n",
    "        X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        data = pd.concat([X, y], axis=1).dropna()\n",
    "\n",
    "        if data.shape[0] >= 30:\n",
    "            X_clean = data[predictors].astype(float)\n",
    "            y_clean = data[target_col].astype(float)\n",
    "\n",
    "            X_clean = sm.add_constant(X_clean)\n",
    "\n",
    "            try:\n",
    "                model = sm.Logit(y_clean, X_clean).fit(disp=0)\n",
    "                pseudo_r2 = model.prsquared\n",
    "                results.append({\n",
    "                    \"Item\": target_col,\n",
    "                    \"Pseudo R¬≤\": round(pseudo_r2, 4),\n",
    "                    \"n_obs\": data.shape[0]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Item\": target_col,\n",
    "                    \"Pseudo R¬≤\": \"Error\",\n",
    "                    \"n_obs\": data.shape[0],\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Ejecutar para cada parte\n",
    "predictive_df_part2 = run_predictive_missingness(df, \"UPDRS2.\")\n",
    "\n",
    "\n",
    "# Visualizar\n",
    "print(\"Parte II:\")\n",
    "print(predictive_df_part2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC2tRB7KI_Ss"
   },
   "source": [
    "## ‚öôÔ∏è Imputabilidad de √≠tems ‚Äî Parte II\n",
    "Eval√∫a si cada √≠tem cumple criterios m√≠nimos de imputabilidad (tipo num√©rico, rango 0-4, < 20 % missing).  \n",
    "El resultado clasifica cada variable como *imputable* o *no imputable*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iANClRdI_aN"
   },
   "outputs": [],
   "source": [
    "# Umbral de % de missing aceptable\n",
    "umbral_missing = 20\n",
    "\n",
    "def evaluar_imputabilidad(df, prefix):\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    imputabilidad = []\n",
    "    for col in cols:\n",
    "        es_numerico = pd.api.types.is_numeric_dtype(df[col])\n",
    "        en_rango = df[col].dropna().isin([0, 1, 2, 3, 4]).all()\n",
    "        missing_pct = df[col].isna().mean() * 100\n",
    "        imputable = es_numerico and en_rango and (missing_pct < umbral_missing)\n",
    "        imputabilidad.append({\n",
    "            \"√çtem\": col,\n",
    "            \"Imputable\": imputable,\n",
    "            \"% Missing\": round(missing_pct, 2),\n",
    "            \"Num√©rico\": es_numerico,\n",
    "            \"Rango 0‚Äì4\": en_rango\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(imputabilidad)\n",
    "\n",
    "# Ejecutar para cada parte\n",
    "imputabilidad_part2 = evaluar_imputabilidad(df, \"UPDRS2.\")\n",
    "\n",
    "\n",
    "# Mostrar\n",
    "print(\"Parte II:\")\n",
    "print(imputabilidad_part2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOJyIZcLJMcA"
   },
   "source": [
    "## ü§ñ Sugerencia de m√©todo de imputaci√≥n ‚Äî Parte II\n",
    "Propone el m√©todo m√°s adecuado (Moda, Mediana por grupo, KNN, etc.) seg√∫n el porcentaje de celdas faltantes.  \n",
    "Permite estandarizar el tratamiento de datos ausentes de la Parte II.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9Y9aeuoJMlC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funci√≥n de recomendaci√≥n de imputaci√≥n\n",
    "def sugerir_metodo_imputacion(missing_pct, tipo=\"ordinal\", escala=(0, 4)):\n",
    "    if missing_pct > 30:\n",
    "        return \"No imputar (>30% missing)\"\n",
    "    elif tipo == \"ordinal\" and escala == (0, 4):\n",
    "        if missing_pct < 5:\n",
    "            return \"Moda\"\n",
    "        elif missing_pct < 20:\n",
    "            return \"Mediana por grupo o regresi√≥n ordinal\"\n",
    "        else:\n",
    "            return \"KNN imputaci√≥n\"\n",
    "    else:\n",
    "        return \"Evaluar manualmente\"\n",
    "\n",
    "# Funci√≥n para aplicar a cada parte\n",
    "def generar_sugerencias(df, prefix):\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "    sugerencias = []\n",
    "    for col in cols:\n",
    "        pct_missing = df[col].isna().mean() * 100\n",
    "        metodo = sugerir_metodo_imputacion(pct_missing)\n",
    "        sugerencias.append({\n",
    "            \"√çtem\": col,\n",
    "            \"% Missing\": round(pct_missing, 2),\n",
    "            \"M√©todo sugerido\": metodo\n",
    "        })\n",
    "    return pd.DataFrame(sugerencias)\n",
    "\n",
    "# Aplicar y mostrar resultados\n",
    "sugerencias_updrs2 = generar_sugerencias(df, \"UPDRS2.\")\n",
    "\n",
    "print(\"Sugerencias Parte II:\")\n",
    "print(sugerencias_updrs2.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlPu_SJ3GKHt"
   },
   "source": [
    "## üî¢ MDS-UPDRS Parte III\n",
    "\n",
    "Esta secci√≥n aborda la **Parte III (Exploraci√≥n motora)**, con m√°s √≠tems y mayor riesgo de valores ausentes.  \n",
    "Se aplican los mismos procedimientos: validaci√≥n, an√°lisis de faltantes, MCAR test, modelo predictivo, imputabilidad y sugerencia de m√©todo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bdu8_na8GKdZ"
   },
   "outputs": [],
   "source": [
    "# Identificar columnas de Parte III\n",
    "updrs3_cols = [col for col in df.columns if col.startswith(\"UPDRS3.\")]\n",
    "updrs3_cols = sorted(updrs3_cols)  # Ordenar por si est√°n desordenadas\n",
    "\n",
    "# Asegurar que las columnas sean num√©ricas\n",
    "df[updrs3_cols] = df[updrs3_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Validar valor individual entre 0 y 4\n",
    "for col in updrs3_cols:\n",
    "    validation_results_updrs[f\"{col}.valido\"] = df[col].isin([0, 1, 2, 3, 4])\n",
    "\n",
    "# Validar que haya exactamente 33 √≠tems v√°lidos\n",
    "validation_results_updrs[\"UPDRS3.completo\"] = df[updrs3_cols].apply(\n",
    "    lambda row: row.dropna().isin([0, 1, 2, 3, 4]).sum() == 33, axis=1\n",
    ")\n",
    "\n",
    "# Agregar columna de error general para la Parte III\n",
    "validation_results_updrs[\"UPDRS3.con_errores\"] = ~validation_results_updrs[\n",
    "    [f\"{col}.valido\" for col in updrs3_cols] + [\"UPDRS3.completo\"]\n",
    "].all(axis=1)\n",
    "\n",
    "# Mostrar filas con errores\n",
    "errores_updrs3 = validation_results_updrs[validation_results_updrs[\"UPDRS3.con_errores\"]]\n",
    "\n",
    "# Visualizar errores\n",
    "print(\"Errores detectados en UPDRS Parte III:\")\n",
    "display(errores_updrs3.head(10))  # O usa .to_excel si deseas exportar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGsS1xdYG4Sc"
   },
   "source": [
    "## Porcentaje de valores faltantes por √≠tem ‚Äî MDS-UPDRS Parte III\n",
    "Eval√∫a el porcentaje de valores ausentes por cada √≠tem, detectando posibles √°reas problem√°ticas antes de imputaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tS-OHl7HYiw"
   },
   "outputs": [],
   "source": [
    "updrs3_cols = sorted([col for col in df.columns if col.startswith(\"UPDRS3.\")])\n",
    "missing_percent_updrs3 = df[updrs3_cols].isna().mean().round(3) * 100\n",
    "missing_percent_updrs3_df = missing_percent_updrs3.reset_index()\n",
    "missing_percent_updrs3_df.columns = [\"√çtem\", \"% Missing\"]\n",
    "print(\"\\nParte III:\")\n",
    "print(missing_percent_updrs3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYZxxyW3HYva"
   },
   "source": [
    "## üß™ Test de Little ‚Äî MCAR (Parte III)\n",
    "Verifica si los valores faltantes en la Parte II ocurren de forma completamente aleatoria.  \n",
    "Si *p* ‚â• 0.05 ‚Üí posiblemente MCAR; si *p* < 0.05 ‚Üí evidencia de no MCAR.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8l228-9UHY5Q"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "\n",
    "# Asegurar que todas las columnas relevantes est√©n en formato num√©rico\n",
    "def run_ttests_for_part(df, prefix):\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    ttest_results = []\n",
    "\n",
    "    for target_col in cols:\n",
    "        row_results = {\"item\": target_col}\n",
    "        for other_col in cols:\n",
    "            if other_col != target_col:\n",
    "                group1 = df[df[other_col].isnull()][target_col].dropna()\n",
    "                group2 = df[df[other_col].notnull()][target_col].dropna()\n",
    "\n",
    "                if len(group1) >= 5 and len(group2) >= 5:\n",
    "                    stat, p = ttest_ind(group1, group2, equal_var=False, nan_policy='omit')\n",
    "                    row_results[f\"p_vs_{other_col}\"] = round(p, 4)\n",
    "                else:\n",
    "                    row_results[f\"p_vs_{other_col}\"] = None\n",
    "        ttest_results.append(row_results)\n",
    "\n",
    "    return pd.DataFrame(ttest_results)\n",
    "\n",
    "# Aplicar a cada parte\n",
    "\n",
    "ttest_df_part3 = run_ttests_for_part(df, \"UPDRS3.\")\n",
    "\n",
    "# Mostrar resultados\n",
    "\n",
    "print(\"T-test resultados Parte III:\")\n",
    "display(ttest_df_part3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PRPj4VBIT7R"
   },
   "source": [
    "## üßÆ Modelo predictivo del patr√≥n de missing ‚Äî MDS-UPDRS Parte III\n",
    "Se utiliza regresi√≥n log√≠stica para estimar si la presencia de datos faltantes en un √≠tem puede predecirse por otros,  \n",
    "identificando patrones MAR/MNAR (dependencia estructurada entre variables).\n",
    "\n",
    "\n",
    "Interpretaci√≥n del output Pseudo R¬≤ bajo (< 0.05): la variable objetivo (missing o no) no se puede predecir bien ‚Üí evidencia de MCAR.\n",
    "\n",
    "Pseudo R¬≤ moderado/alto (> 0.1): el patr√≥n de missing puede estar relacionado con otras variables ‚Üí MAR o MNAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6c8DTXSIUC5"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "def run_predictive_missingness(df, prefix):\n",
    "    # Identificar columnas que comienzan con el prefijo y no son totales\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "\n",
    "    # Asegurar que sean num√©ricos\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for target_col in cols:\n",
    "        y = df[target_col].isnull().astype(int)\n",
    "        predictors = [col for col in cols if col != target_col]\n",
    "\n",
    "        X = df[predictors].copy()\n",
    "        X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        data = pd.concat([X, y], axis=1).dropna()\n",
    "\n",
    "        if data.shape[0] >= 30:\n",
    "            X_clean = data[predictors].astype(float)\n",
    "            y_clean = data[target_col].astype(float)\n",
    "\n",
    "            X_clean = sm.add_constant(X_clean)\n",
    "\n",
    "            try:\n",
    "                model = sm.Logit(y_clean, X_clean).fit(disp=0)\n",
    "                pseudo_r2 = model.prsquared\n",
    "                results.append({\n",
    "                    \"Item\": target_col,\n",
    "                    \"Pseudo R¬≤\": round(pseudo_r2, 4),\n",
    "                    \"n_obs\": data.shape[0]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Item\": target_col,\n",
    "                    \"Pseudo R¬≤\": \"Error\",\n",
    "                    \"n_obs\": data.shape[0],\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Ejecutar para cada parte\n",
    "\n",
    "predictive_df_part3 = run_predictive_missingness(df, \"UPDRS3.\")\n",
    "\n",
    "\n",
    "# Visualizar\n",
    "\n",
    "print(\"\\nParte III:\")\n",
    "print(predictive_df_part3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shLEulJhJCLv"
   },
   "source": [
    "## ‚öôÔ∏è Imputabilidad de √≠tems ‚Äî Parte III\n",
    "Eval√∫a si cada √≠tem cumple criterios m√≠nimos de imputabilidad (tipo num√©rico, rango 0-4, < 20 % missing).  \n",
    "El resultado clasifica cada variable como *imputable* o *no imputable*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXKv850uJCW4"
   },
   "outputs": [],
   "source": [
    "# Umbral de % de missing aceptable\n",
    "umbral_missing = 20\n",
    "\n",
    "def evaluar_imputabilidad(df, prefix):\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    imputabilidad = []\n",
    "    for col in cols:\n",
    "        es_numerico = pd.api.types.is_numeric_dtype(df[col])\n",
    "        en_rango = df[col].dropna().isin([0, 1, 2, 3, 4]).all()\n",
    "        missing_pct = df[col].isna().mean() * 100\n",
    "        imputable = es_numerico and en_rango and (missing_pct < umbral_missing)\n",
    "        imputabilidad.append({\n",
    "            \"√çtem\": col,\n",
    "            \"Imputable\": imputable,\n",
    "            \"% Missing\": round(missing_pct, 2),\n",
    "            \"Num√©rico\": es_numerico,\n",
    "            \"Rango 0‚Äì4\": en_rango\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(imputabilidad)\n",
    "\n",
    "# Ejecutar para cada parte\n",
    "\n",
    "imputabilidad_part3 = evaluar_imputabilidad(df, \"UPDRS3.\")\n",
    "\n",
    "\n",
    "# Mostrar\n",
    "\n",
    "print(\"\\nParte III:\")\n",
    "print(imputabilidad_part3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGxMxfywJQbX"
   },
   "source": [
    "## ü§ñ Sugerencia de m√©todo de imputaci√≥n ‚Äî Parte III\n",
    "Propone el m√©todo m√°s adecuado (Moda, Mediana por grupo, KNN, etc.) seg√∫n el porcentaje de celdas faltantes.  \n",
    "Permite estandarizar el tratamiento de datos ausentes de la Parte II.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntFf1uQDJQiv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funci√≥n de recomendaci√≥n de imputaci√≥n\n",
    "def sugerir_metodo_imputacion(missing_pct, tipo=\"ordinal\", escala=(0, 4)):\n",
    "    if missing_pct > 30:\n",
    "        return \"No imputar (>30% missing)\"\n",
    "    elif tipo == \"ordinal\" and escala == (0, 4):\n",
    "        if missing_pct < 5:\n",
    "            return \"Moda\"\n",
    "        elif missing_pct < 20:\n",
    "            return \"Mediana por grupo o regresi√≥n ordinal\"\n",
    "        else:\n",
    "            return \"KNN imputaci√≥n\"\n",
    "    else:\n",
    "        return \"Evaluar manualmente\"\n",
    "\n",
    "# Funci√≥n para aplicar a cada parte\n",
    "def generar_sugerencias(df, prefix):\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "    sugerencias = []\n",
    "    for col in cols:\n",
    "        pct_missing = df[col].isna().mean() * 100\n",
    "        metodo = sugerir_metodo_imputacion(pct_missing)\n",
    "        sugerencias.append({\n",
    "            \"√çtem\": col,\n",
    "            \"% Missing\": round(pct_missing, 2),\n",
    "            \"M√©todo sugerido\": metodo\n",
    "        })\n",
    "    return pd.DataFrame(sugerencias)\n",
    "\n",
    "# Aplicar y mostrar resultados\n",
    "sugerencias_updrs3 = generar_sugerencias(df, \"UPDRS3.\")\n",
    "\n",
    "\n",
    "print(\"\\nSugerencias Parte III:\")\n",
    "print(sugerencias_updrs3.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaMi1XFxGSg6"
   },
   "source": [
    "## ‚öñÔ∏è MDS-UPDRS Parte IV\n",
    "\n",
    "La **Parte IV (Complicaciones motoras)** tiene menos √≠tems, por lo que se espera menor proporci√≥n de valores faltantes.  \n",
    "Se aplican los mismos pasos de verificaci√≥n e imputaci√≥n utilizados en las Partes I‚ÄìIII para garantizar consistencia del dataset completo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZguIhMqGSwn"
   },
   "outputs": [],
   "source": [
    "# Identificar columnas de Parte IV\n",
    "updrs4_cols = [col for col in df.columns if col.startswith(\"UPDRS4.\")]\n",
    "updrs4_cols = sorted(updrs4_cols)  # Ordenar por si est√°n desordenadas\n",
    "\n",
    "# Asegurar que las columnas sean num√©ricas\n",
    "df[updrs4_cols] = df[updrs4_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Validar valor individual entre 0 y 4\n",
    "for col in updrs4_cols:\n",
    "    validation_results_updrs[f\"{col}.valido\"] = df[col].isin([0, 1, 2, 3, 4])\n",
    "\n",
    "# Validar que haya exactamente 6 √≠tems v√°lidos\n",
    "validation_results_updrs[\"UPDRS4.completo\"] = df[updrs4_cols].apply(\n",
    "    lambda row: row.dropna().isin([0, 1, 2, 3, 4]).sum() == 6, axis=1\n",
    ")\n",
    "\n",
    "# Agregar columna de error general para la Parte IV\n",
    "validation_results_updrs[\"UPDRS4.con_errores\"] = ~validation_results_updrs[\n",
    "    [f\"{col}.valido\" for col in updrs4_cols] + [\"UPDRS4.completo\"]\n",
    "].all(axis=1)\n",
    "\n",
    "# Mostrar filas con errores\n",
    "errores_updrs4 = validation_results_updrs[validation_results_updrs[\"UPDRS4.con_errores\"]]\n",
    "\n",
    "# Visualizar errores\n",
    "print(\"Errores detectados en UPDRS Parte IV:\")\n",
    "display(errores_updrs4.head(10))  # O usa .to_excel si deseas exportar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAptuM3jG6g1"
   },
   "source": [
    "## Porcentaje de valores faltantes por √≠tem ‚Äî MDS-UPDRS Parte IV\n",
    "Eval√∫a el porcentaje de valores ausentes por cada √≠tem, detectando posibles √°reas problem√°ticas antes de imputaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TE447_2YHbWK"
   },
   "outputs": [],
   "source": [
    "updrs4_cols = sorted([col for col in df.columns if col.startswith(\"UPDRS4.\")])\n",
    "missing_percent_updrs4 = df[updrs4_cols].isna().mean().round(3) * 100\n",
    "missing_percent_updrs4_df = missing_percent_updrs4.reset_index()\n",
    "missing_percent_updrs4_df.columns = [\"√çtem\", \"% Missing\"]\n",
    "print(\"\\nParte IV:\")\n",
    "print(missing_percent_updrs4_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kqpjulXHbdU"
   },
   "source": [
    "## üß™ Test de Little ‚Äî MCAR (Parte IV)\n",
    "Verifica si los valores faltantes en la Parte II ocurren de forma completamente aleatoria.  \n",
    "Si *p* ‚â• 0.05 ‚Üí posiblemente MCAR; si *p* < 0.05 ‚Üí evidencia de no MCAR.\n",
    "\n",
    "Si el p-value < 0.05, hay diferencia significativa ‚Üí No MCAR\n",
    "\n",
    "Si el p-value ‚â• 0.05, no hay diferencia ‚Üí Posiblemente MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ztp0ckwHbmA"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "\n",
    "# Asegurar que todas las columnas relevantes est√©n en formato num√©rico\n",
    "def run_ttests_for_part(df, prefix):\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    ttest_results = []\n",
    "\n",
    "    for target_col in cols:\n",
    "        row_results = {\"item\": target_col}\n",
    "        for other_col in cols:\n",
    "            if other_col != target_col:\n",
    "                group1 = df[df[other_col].isnull()][target_col].dropna()\n",
    "                group2 = df[df[other_col].notnull()][target_col].dropna()\n",
    "\n",
    "                if len(group1) >= 5 and len(group2) >= 5:\n",
    "                    stat, p = ttest_ind(group1, group2, equal_var=False, nan_policy='omit')\n",
    "                    row_results[f\"p_vs_{other_col}\"] = round(p, 4)\n",
    "                else:\n",
    "                    row_results[f\"p_vs_{other_col}\"] = None\n",
    "        ttest_results.append(row_results)\n",
    "\n",
    "    return pd.DataFrame(ttest_results)\n",
    "\n",
    "# Aplicar a cada parte\n",
    "\n",
    "ttest_df_part4 = run_ttests_for_part(df, \"UPDRS4.\")\n",
    "\n",
    "# Mostrar resultados\n",
    "\n",
    "\n",
    "print(\"T-test resultados Parte IV:\")\n",
    "display(ttest_df_part4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHTMu-WwIW-R"
   },
   "source": [
    "## üßÆ Modelo predictivo del patr√≥n de missing ‚Äî MDS-UPDRS Parte IV\n",
    "Se utiliza regresi√≥n log√≠stica para estimar si la presencia de datos faltantes en un √≠tem puede predecirse por otros,  \n",
    "identificando patrones MAR/MNAR (dependencia estructurada entre variables).\n",
    "\n",
    "\n",
    "Interpretaci√≥n del output Pseudo R¬≤ bajo (< 0.05): la variable objetivo (missing o no) no se puede predecir bien ‚Üí evidencia de MCAR.\n",
    "\n",
    "Pseudo R¬≤ moderado/alto (> 0.1): el patr√≥n de missing puede estar relacionado con otras variables ‚Üí MAR o MNAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHopgi3KIXIR"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "def run_predictive_missingness(df, prefix):\n",
    "    # Identificar columnas que comienzan con el prefijo y no son totales\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "\n",
    "    # Asegurar que sean num√©ricos\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for target_col in cols:\n",
    "        y = df[target_col].isnull().astype(int)\n",
    "        predictors = [col for col in cols if col != target_col]\n",
    "\n",
    "        X = df[predictors].copy()\n",
    "        X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        data = pd.concat([X, y], axis=1).dropna()\n",
    "\n",
    "        if data.shape[0] >= 30:\n",
    "            X_clean = data[predictors].astype(float)\n",
    "            y_clean = data[target_col].astype(float)\n",
    "\n",
    "            X_clean = sm.add_constant(X_clean)\n",
    "\n",
    "            try:\n",
    "                model = sm.Logit(y_clean, X_clean).fit(disp=0)\n",
    "                pseudo_r2 = model.prsquared\n",
    "                results.append({\n",
    "                    \"Item\": target_col,\n",
    "                    \"Pseudo R¬≤\": round(pseudo_r2, 4),\n",
    "                    \"n_obs\": data.shape[0]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Item\": target_col,\n",
    "                    \"Pseudo R¬≤\": \"Error\",\n",
    "                    \"n_obs\": data.shape[0],\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Ejecutar para cada parte\n",
    "predictive_df_part4 = run_predictive_missingness(df, \"UPDRS4.\")\n",
    "\n",
    "# Visualizar\n",
    "\n",
    "print(\"\\nParte IV:\")\n",
    "print(predictive_df_part4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbMzYIFDJE6H"
   },
   "source": [
    "## ‚öôÔ∏è Imputabilidad de √≠tems ‚Äî Parte IV\n",
    "Eval√∫a si cada √≠tem cumple criterios m√≠nimos de imputabilidad (tipo num√©rico, rango 0-4, < 20 % missing).  \n",
    "El resultado clasifica cada variable como *imputable* o *no imputable*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7TjIv2XJFEj"
   },
   "outputs": [],
   "source": [
    "# Umbral de % de missing aceptable\n",
    "umbral_missing = 20\n",
    "\n",
    "def evaluar_imputabilidad(df, prefix):\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    imputabilidad = []\n",
    "    for col in cols:\n",
    "        es_numerico = pd.api.types.is_numeric_dtype(df[col])\n",
    "        en_rango = df[col].dropna().isin([0, 1, 2, 3, 4]).all()\n",
    "        missing_pct = df[col].isna().mean() * 100\n",
    "        imputable = es_numerico and en_rango and (missing_pct < umbral_missing)\n",
    "        imputabilidad.append({\n",
    "            \"√çtem\": col,\n",
    "            \"Imputable\": imputable,\n",
    "            \"% Missing\": round(missing_pct, 2),\n",
    "            \"Num√©rico\": es_numerico,\n",
    "            \"Rango 0‚Äì4\": en_rango\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(imputabilidad)\n",
    "\n",
    "# Ejecutar para cada parte\n",
    "\n",
    "imputabilidad_part4 = evaluar_imputabilidad(df, \"UPDRS4.\")\n",
    "\n",
    "# Mostrar\n",
    "\n",
    "print(\"\\nParte IV:\")\n",
    "print(imputabilidad_part4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57ukFpfQJTwp"
   },
   "source": [
    "## ü§ñ Sugerencia de m√©todo de imputaci√≥n ‚Äî Parte IV\n",
    "Propone el m√©todo m√°s adecuado (Moda, Mediana por grupo, KNN, etc.) seg√∫n el porcentaje de celdas faltantes.  \n",
    "Permite estandarizar el tratamiento de datos ausentes de la Parte IV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBDFshbJJT42"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funci√≥n de recomendaci√≥n de imputaci√≥n\n",
    "def sugerir_metodo_imputacion(missing_pct, tipo=\"ordinal\", escala=(0, 4)):\n",
    "    if missing_pct > 30:\n",
    "        return \"No imputar (>30% missing)\"\n",
    "    elif tipo == \"ordinal\" and escala == (0, 4):\n",
    "        if missing_pct < 5:\n",
    "            return \"Moda\"\n",
    "        elif missing_pct < 20:\n",
    "            return \"Mediana por grupo o regresi√≥n ordinal\"\n",
    "        else:\n",
    "            return \"KNN imputaci√≥n\"\n",
    "    else:\n",
    "        return \"Evaluar manualmente\"\n",
    "\n",
    "# Funci√≥n para aplicar a cada parte\n",
    "def generar_sugerencias(df, prefix):\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "    sugerencias = []\n",
    "    for col in cols:\n",
    "        pct_missing = df[col].isna().mean() * 100\n",
    "        metodo = sugerir_metodo_imputacion(pct_missing)\n",
    "        sugerencias.append({\n",
    "            \"√çtem\": col,\n",
    "            \"% Missing\": round(pct_missing, 2),\n",
    "            \"M√©todo sugerido\": metodo\n",
    "        })\n",
    "    return pd.DataFrame(sugerencias)\n",
    "\n",
    "# Aplicar y mostrar resultados\n",
    "\n",
    "sugerencias_updrs4 = generar_sugerencias(df, \"UPDRS4.\")\n",
    "\n",
    "\n",
    "print(\"\\nSugerencias Parte IV:\")\n",
    "print(sugerencias_updrs4.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLePC_IoMB2T"
   },
   "source": [
    "## üìã Resumen de sugerencias de imputaci√≥n\n",
    "\n",
    "En esta secci√≥n se consolidan las recomendaciones de imputaci√≥n para **todas las partes de la MDS-UPDRS (I‚ÄìIV)**.  \n",
    "El objetivo es automatizar la selecci√≥n de estrategias seg√∫n el tipo de √≠tem, su rango (0‚Äì4) y el porcentaje de datos faltantes.\n",
    "\n",
    "Cada parte genera su propio resumen con los siguientes campos:\n",
    "\n",
    "- **√çtem:** nombre de la variable.  \n",
    "- **% Missing:** proporci√≥n de valores faltantes.  \n",
    "- **M√©todo sugerido:** t√©cnica recomendada para imputar (o no imputar) seg√∫n criterios definidos.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UZtfS6kMB9l"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funci√≥n de recomendaci√≥n\n",
    "def sugerir_metodo_imputacion(missing_pct, tipo=\"ordinal\", escala=(0, 4)):\n",
    "    if missing_pct > 30:\n",
    "        return \"No imputar (>30% missing)\"\n",
    "    elif tipo == \"ordinal\" and escala == (0, 4):\n",
    "        if missing_pct < 5:\n",
    "            return \"Moda\"\n",
    "        elif missing_pct < 20:\n",
    "            return \"Mediana por grupo o regresi√≥n ordinal\"\n",
    "        else:\n",
    "            return \"KNN imputaci√≥n\"\n",
    "    else:\n",
    "        return \"Evaluar manualmente\"\n",
    "\n",
    "# Funci√≥n para generar recomendaciones\n",
    "def generar_sugerencias(df, prefix):\n",
    "    cols = sorted([col for col in df.columns if col.startswith(prefix) and not col.endswith(\"TOTAL\")])\n",
    "    sugerencias = []\n",
    "    for col in cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # asegurar tipo num√©rico\n",
    "        pct_missing = df[col].isna().mean() * 100\n",
    "        metodo = sugerir_metodo_imputacion(pct_missing)\n",
    "        sugerencias.append({\n",
    "            \"√çtem\": col,\n",
    "            \"% Missing\": round(pct_missing, 2),\n",
    "            \"M√©todo sugerido\": metodo\n",
    "        })\n",
    "    return pd.DataFrame(sugerencias)\n",
    "\n",
    "# Aplicar a todas las partes\n",
    "sugerencias1 = generar_sugerencias(df, \"UPDRS1.\")\n",
    "sugerencias2 = generar_sugerencias(df, \"UPDRS2.\")\n",
    "sugerencias3 = generar_sugerencias(df, \"UPDRS3.\")\n",
    "sugerencias4 = generar_sugerencias(df, \"UPDRS4.\")\n",
    "\n",
    "# Funci√≥n para colorear bonito\n",
    "def estilo_color(df):\n",
    "    def highlight_method(val):\n",
    "        if \"No imputar\" in val:\n",
    "            return 'background-color: #ffcccc'\n",
    "        elif \"KNN\" in val:\n",
    "            return 'background-color: #fff2cc'\n",
    "        elif \"Mediana\" in val:\n",
    "            return 'background-color: #ccffcc'\n",
    "        elif \"Moda\" in val:\n",
    "            return 'background-color: #cce5ff'\n",
    "        else:\n",
    "            return ''\n",
    "    return df.style.applymap(highlight_method, subset=[\"M√©todo sugerido\"]).format({\"% Missing\": \"{:.2f}\"})\n",
    "\n",
    "# Mostrar\n",
    "print(\"Parte I\")\n",
    "display(estilo_color(sugerencias1))\n",
    "\n",
    "print(\"Parte II\")\n",
    "display(estilo_color(sugerencias2))\n",
    "\n",
    "print(\"Parte III\")\n",
    "display(estilo_color(sugerencias3))\n",
    "\n",
    "print(\"Parte IV\")\n",
    "display(estilo_color(sugerencias4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIuMzURGtdPi"
   },
   "source": [
    "## Clasificaci√≥n de severidad por puntos de corte (triangulaci√≥n)\n",
    "\n",
    "Este bloque clasifica la severidad por **parte** de la MDS-UPDRS y una **severidad global** basada en la categor√≠a m√°s alta entre I‚ÄìIV.  \n",
    "Los puntos de corte provienen de una triangulaci√≥n (literatura + distribuci√≥n emp√≠rica). Ajusta los umbrales a tu cohorte si es necesario.\n",
    "\n",
    "### Puntos de corte propuestos\n",
    "| Parte | Leve (‚â§) | Moderada (‚â§) | Grave (> moderada) |\n",
    "|------:|---------:|-------------:|--------------------:|\n",
    "| I     | 10       | 21           |                     |\n",
    "| II    | 12       | 29           |                     |\n",
    "| III   | 32       | 58           |                     |\n",
    "| IV    | 4        | 12           |                     |\n",
    "\n",
    "> Regla: si el puntaje de la parte ‚â§ *mild_max* ‚Üí **leve**; si ‚â§ *mod_max* ‚Üí **moderada**; si > *mod_max* ‚Üí **grave**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5eGS0krtdeW"
   },
   "outputs": [],
   "source": [
    "# --- 1. Definir puntos de corte (triangulaci√≥n del art√≠culo) ---------------\n",
    "CUTS = {\n",
    "    \"I\":   {\"mild_max\": 10, \"mod_max\": 21},\n",
    "    \"II\":  {\"mild_max\": 12, \"mod_max\": 29},\n",
    "    \"III\": {\"mild_max\": 32, \"mod_max\": 58},\n",
    "    \"IV\":  {\"mild_max\":  4, \"mod_max\": 12},\n",
    "}\n",
    "\n",
    "def clasificar_parte(score, cut):\n",
    "    if score <= cut[\"mild_max\"]:\n",
    "        return \"leve\"\n",
    "    elif score <= cut[\"mod_max\"]:\n",
    "        return \"moderada\"\n",
    "    else:\n",
    "        return \"grave\"\n",
    "\n",
    "# --- 2. Etiquetar severidad por parte ---------------------------------------\n",
    "for parte in [\"I\", \"II\", \"III\", \"IV\"]:\n",
    "    col_score = f\"MDS_UPDRS_{parte}\"\n",
    "    col_sev   = f\"sev_{parte}\"\n",
    "    df_clean[col_sev] = df_clean[col_score].apply(lambda x: clasificar_parte(x, CUTS[parte]))\n",
    "\n",
    "# --- 3. Severidad global (opcional) -----------------------------------------\n",
    "# Regla pr√°ctica: la categor√≠a m√°s alta entre las cuatro partes\n",
    "niveles = {\"leve\": 1, \"moderada\": 2, \"grave\": 3}\n",
    "\n",
    "def severidad_global(row):\n",
    "    nivel_max = max(row[[f\"sev_{p}\" for p in [\"I\",\"II\",\"III\",\"IV\"]]],\n",
    "                    key=lambda x: niveles[x])\n",
    "    return nivel_max\n",
    "\n",
    "df_clean[\"sev_global\"] = df_clean.apply(severidad_global, axis=1)\n",
    "\n",
    "# --- 4. Vista r√°pida ---------------------------------------------------------\n",
    "display(df_clean[[\"num.consec\", \"fecha.eval\",\n",
    "                  \"MDS_UPDRS_I\", \"MDS_UPDRS_II\", \"MDS_UPDRS_III\", \"MDS_UPDRS_IV\",\n",
    "                  \"sev_I\", \"sev_II\", \"sev_III\", \"sev_IV\", \"sev_global\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZVp2h0wqhvS"
   },
   "source": [
    "## üìà M√©tricas longitudinales: deltas y pendiente anual\n",
    "\n",
    "Este bloque calcula **variaciones intraindividuales (Œî)** y la **pendiente anualizada** de las puntuaciones MDS-UPDRS  \n",
    "para evaluar progresi√≥n cl√≠nica en seguimientos longitudinales.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Preprocesamiento\n",
    "1. **Conversi√≥n de fechas:** se transforma `fecha.eval` a formato `datetime`.  \n",
    "2. **Normalizaci√≥n de columnas num√©ricas:** todas las columnas `MDS_UPDRS_*` se convierten a tipo num√©rico (`float`).  \n",
    "3. **Verificaci√≥n del total:** si la columna `MDS_UPDRS_TOTAL` no existe, se genera autom√°ticamente como la suma de las partes I‚ÄìIV.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚è≥ Orden cronol√≥gico y c√°lculo temporal\n",
    "- Se ordenan las observaciones por sujeto (`num.consec`) y fecha.  \n",
    "- Se calcula el **tiempo transcurrido en a√±os** desde la primera visita individual mediante:\n",
    "  \\[\n",
    "  \\text{tiempo\\_a√±os} = \\frac{(\\text{fecha.eval} - \\text{fecha.inicial})}{365.25}\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Deltas intraindividuales\n",
    "- Se calcula la **variaci√≥n respecto a la l√≠nea base** (primera visita) para cada parte y para el total:  \n",
    "  \\[\n",
    "  \\Delta_{\\text{parte}} = \\text{UPDRS}_{\\text{parte}}(t) - \\text{UPDRS}_{\\text{parte}}(t_0)\n",
    "  \\]\n",
    "- Estas m√©tricas permiten estimar la progresi√≥n sintom√°tica a lo largo del tiempo.\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Variables resultantes\n",
    "| Variable | Descripci√≥n |\n",
    "|-----------|-------------|\n",
    "| `tiempo_a√±os` | Tiempo desde la primera evaluaci√≥n (a√±os) |\n",
    "| `Œî_I`, `Œî_II`, `Œî_III`, `Œî_TOTAL` | Cambios absolutos por parte y global |\n",
    "| `MDS_UPDRS_TOTAL` | Puntaje total sumado autom√°ticamente si no exist√≠a |\n",
    "\n",
    "---\n",
    "\n",
    "> **Interpretaci√≥n:**  \n",
    "> - Un Œî positivo indica **empeoramiento** en la puntuaci√≥n.  \n",
    "> - La pendiente anual puede estimarse aplicando regresi√≥n lineal (`Œî / tiempo_a√±os`) o modelos mixtos seg√∫n la estructura del seguimiento.  \n",
    "> - Este bloque es fundamental para construir m√©tricas de progresi√≥n y modelado longitudinal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpnzVU0IqiGm"
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# --- 0. Asegura tipos --------------------------------------------------------\n",
    "# 0.1 Fechas\n",
    "df_clean[\"fecha.eval\"] = pd.to_datetime(df_clean[\"fecha.eval\"], errors=\"coerce\")\n",
    "\n",
    "# 0.2 Puntajes UPDRS: fuerza a num√©rico; lo que no sea n√∫mero se vuelve NaN\n",
    "score_cols = [c for c in df_clean.columns if c.startswith(\"MDS_UPDRS_\")]\n",
    "df_clean[score_cols] = df_clean[score_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# 0.3 Si a√∫n no existe el total, cr√©alo r√°pido\n",
    "if \"MDS_UPDRS_TOTAL\" not in df_clean.columns:\n",
    "    df_clean[\"MDS_UPDRS_TOTAL\"] = df_clean[[f\"MDS_UPDRS_{p}\"\n",
    "                                            for p in [\"I\", \"II\", \"III\", \"IV\"]]].sum(axis=1)\n",
    "\n",
    "# --- 1. Orden cronol√≥gico ----------------------------------------------------\n",
    "df_clean = df_clean.sort_values([\"num.consec\", \"fecha.eval\"])\n",
    "\n",
    "# --- 2. Tiempo (a√±os) desde la primera visita individual ---------------------\n",
    "df_clean[\"tiempo_a√±os\"] = (\n",
    "    df_clean.groupby(\"num.consec\")[\"fecha.eval\"]\n",
    "            .transform(lambda x: (x - x.min()).dt.total_seconds() / (365.25 * 24 * 3600))\n",
    ")\n",
    "\n",
    "# --- 3. Œî vs. l√≠nea base -----------------------------------------------------\n",
    "for parte in [\"I\", \"II\", \"III\", \"TOTAL\"]:\n",
    "    base = df_clean.groupby(\"num.consec\")[f\"MDS_UPDRS_{parte}\"].transform(\"first\")\n",
    "    df_clean[f\"Œî_{parte}\"] = df_clean[f\"MDS_UPDRS_{parte}\"] - base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualizaci√≥n r√°pida de los resultados (`df_clean`)\n",
    "\n",
    "Este bloque permite revisar de forma inmediata la coherencia general de los datos procesados,  \n",
    "la distribuci√≥n de severidad global en la √∫ltima visita de cada paciente y la tendencia media del puntaje total de MDS-UPDRS en el tiempo.\n",
    "\n",
    "---\n",
    "\n",
    "### 1Ô∏è‚É£ Vista r√°pida de registros procesados\n",
    "Se inspeccionan las primeras filas relevantes de la base limpia (`df_clean`), mostrando:\n",
    "- **Identificador del paciente (`num.consec`)**\n",
    "- **Fecha de evaluaci√≥n (`fecha.eval`)**\n",
    "- **Puntaje total (`MDS_UPDRS_TOTAL`)**\n",
    "- **Delta total respecto a la l√≠nea base (`Œî_TOTAL`)**\n",
    "- **Clasificaci√≥n de severidad global (`sev_global`)**\n",
    "\n",
    "> Esta vista sirve para verificar que la estructura de columnas y los c√°lculos previos se realizaron correctamente.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Distribuci√≥n de la severidad global (√∫ltima visita)\n",
    "Se obtiene la categor√≠a de **severidad global** de la √∫ltima visita de cada paciente y se calcula la distribuci√≥n de frecuencias:\n",
    "- Permite identificar cu√°ntos casos est√°n en fases **leves**, **moderadas** o **graves**.\n",
    "- Es √∫til como control de coherencia y para visualizar el **estado cl√≠nico final de la cohorte**.\n",
    "\n",
    "```python\n",
    "print(\"Distribuci√≥n de severidad global (√∫ltima visita):\")\n",
    "print(ultima_visita[\"sev_global\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAbVeR0eybZ6"
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# VISUALIZACI√ìN R√ÅPIDA DE LOS RESULTADOS EN df_clean\n",
    "# ---------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Vista r√°pida de las primeras visitas procesadas\n",
    "cols_vista = [\"num.consec\", \"fecha.eval\",\n",
    "              \"MDS_UPDRS_TOTAL\", \"Œî_TOTAL\", \"sev_global\"]\n",
    "\n",
    "if 'df_clean' not in globals():\n",
    "    raise NameError(\"No se encontr√≥ la variable `df_clean`. \"\n",
    "                    \"Ejecuta primero el script de procesamiento.\")\n",
    "\n",
    "display(df_clean[cols_vista].head(10))\n",
    "\n",
    "# 2) Distribuci√≥n de la severidad global (√∫ltima visita por paciente)\n",
    "ultima_visita = (\n",
    "    df_clean.sort_values([\"num.consec\", \"fecha.eval\"])\n",
    "            .groupby(\"num.consec\")\n",
    "            .tail(1)\n",
    ")\n",
    "print(\"\\nDistribuci√≥n de severidad global (√∫ltima visita):\")\n",
    "print(ultima_visita[\"sev_global\"].value_counts())\n",
    "\n",
    "# 3) Progresi√≥n media del puntaje total a lo largo del tiempo\n",
    "mean_prog = (\n",
    "    df_clean.groupby(\"tiempo_a√±os\")[\"Œî_TOTAL\"]\n",
    "            .mean()\n",
    "            .sort_index()\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(mean_prog.index, mean_prog.values, marker='o')\n",
    "plt.xlabel(\"Tiempo (a√±os)\")\n",
    "plt.ylabel(\"Œî MDS-UPDRS Total\")\n",
    "plt.title(\"Progresi√≥n media del MDS-UPDRS Total\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_gyf396qoro"
   },
   "source": [
    "## üéØ Etiquetas de cambio cl√≠nicamente importante (MCID + evento de progresi√≥n)\n",
    "\n",
    "Esta secci√≥n implementa las **banderas de cambio cl√≠nicamente significativo (MCID)** para identificar  \n",
    "mejoras o empeoramientos relevantes en las puntuaciones MDS-UPDRS a nivel individual, as√≠ como un  \n",
    "evento de progresi√≥n motora (+5 puntos en Parte III, estado OFF).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 4.1 Umbrales MCID publicados\n",
    "\n",
    "| Parte | MCID (puntos) | Interpretaci√≥n |\n",
    "|:------|:--------------|:---------------|\n",
    "| I     | ¬±2.5          | Cambio cl√≠nicamente relevante en s√≠ntomas no motores |\n",
    "| II    | ¬±3.0          | Cambio cl√≠nicamente relevante en actividades de la vida diaria |\n",
    "| III (mejora) | ‚Äì3.25 | Mejora significativa del desempe√±o motor |\n",
    "| III (empeora) | +4.63 | Empeoramiento cl√≠nicamente importante del desempe√±o motor |\n",
    "\n",
    "> **Referencia:**  \n",
    "> Horvath et al., *Movement Disorders Clinical Practice*, 2020.  \n",
    "> Li et al., *Parkinsonism & Related Disorders*, 2021.\n",
    "\n",
    "---\n",
    "\n",
    "### üî∏ 4.2 Creaci√≥n de indicadores (flags) MCID\n",
    "\n",
    "Cada variable de delta (`Œî_I`, `Œî_II`, `Œî_III`) se eval√∫a contra los umbrales definidos:  \n",
    "- Si el cambio absoluto excede el MCID ‚Üí **cambio cl√≠nicamente importante**.  \n",
    "- En la Parte III se generan dos indicadores separados:\n",
    "  - `mcid_III_mej`: mejora significativa (‚â§ ‚Äì3.25).  \n",
    "  - `mcid_III_emp`: empeoramiento significativo (‚â• +4.63).\n",
    "\n",
    "Ejemplo de c√°lculo:\n",
    "\n",
    "```python\n",
    "df_clean[\"mcid_I\"]        = df_clean[\"Œî_I\"].abs()   >= MCID[\"I\"]\n",
    "df_clean[\"mcid_II\"]       = df_clean[\"Œî_II\"].abs()  >= MCID[\"II\"]\n",
    "df_clean[\"mcid_III_mej\"]  = df_clean[\"Œî_III\"] <= -MCID[\"III_mej\"]\n",
    "df_clean[\"mcid_III_emp\"]  = df_clean[\"Œî_III\"] >=  MCID[\"III_emp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSGfKED4qoyi"
   },
   "outputs": [],
   "source": [
    "# 4.1 Umbrales publicados\n",
    "MCID = {\n",
    "    \"I\":  2.5,   # ¬±2.5 pts\n",
    "    \"II\": 3.0,   # ¬±3.0 pts\n",
    "    \"III_mej\": 3.25,\n",
    "    \"III_emp\": 4.63\n",
    "}\n",
    "\n",
    "# 4.2 Flags MCID\n",
    "df_clean[\"mcid_I\"]        = df_clean[\"Œî_I\"].abs()  >= MCID[\"I\"]\n",
    "df_clean[\"mcid_II\"]       = df_clean[\"Œî_II\"].abs() >= MCID[\"II\"]\n",
    "df_clean[\"mcid_III_mej\"]  = df_clean[\"Œî_III\"] <= -MCID[\"III_mej\"]\n",
    "df_clean[\"mcid_III_emp\"]  = df_clean[\"Œî_III\"] >=  MCID[\"III_emp\"]\n",
    "\n",
    "# 4.3 Evento de progresi√≥n motora (+5 pts Parte III OFF)\n",
    "df_clean[\"event_progIII\"] = df_clean[\"Œî_III\"] >= 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dxvBhaoq1ia"
   },
   "source": [
    "## ‚è±Ô∏è Pendiente individual y an√°lisis ‚Äútime-to-event‚Äù\n",
    "\n",
    "Esta secci√≥n prepara el entorno para el c√°lculo de **pendientes de progresi√≥n individual** y el an√°lisis de **tiempo hasta evento cl√≠nico (time-to-event)**, t√≠picamente mediante modelos de supervivencia de Cox.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Instalaci√≥n de dependencias\n",
    "Se instala la librer√≠a `lifelines`, ampliamente utilizada en an√°lisis de supervivencia (Kaplan-Meier, CoxPH, etc.):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_22qTddyp87"
   },
   "outputs": [],
   "source": [
    "!pip install -q lifelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiuGdPM1ysz6"
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from lifelines import CoxPHFitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Modelo Mixto Robusto: Pendiente Individual (MDS-UPDRS III)\n",
    "\n",
    "Esta secci√≥n estima la **pendiente individual de progresi√≥n motora** (Parte III de la MDS-UPDRS) mediante un **modelo lineal mixto (Mixed-Effects Model)**, que permite capturar tanto la tendencia general como la variabilidad entre pacientes.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è 0. Preparaci√≥n de los datos\n",
    "1. Se genera una **copia de trabajo** (`df_mlm`) a partir del dataframe limpio (`df_clean`).  \n",
    "2. Se seleccionan las variables necesarias:\n",
    "   - `num.consec` ‚Üí identificador del paciente.  \n",
    "   - `MDS_UPDRS_III` ‚Üí puntuaci√≥n motora.  \n",
    "   - `tiempo_a√±os` ‚Üí tiempo desde la l√≠nea base.  \n",
    "3. Se convierten los tipos de datos y se eliminan valores faltantes.\n",
    "\n",
    "> **Criterio de inclusi√≥n:** solo se conservan pacientes con **‚â• 2 visitas** y **‚â• 2 puntos de tiempo distintos**.\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ 1. Especificaci√≥n del modelo\n",
    "\n",
    "El modelo lineal mixto ajusta la relaci√≥n:\n",
    "\\[\n",
    "\\text{MDS\\_UPDRS\\_III}_{ij} = \\beta_0 + \\beta_1 \\times \\text{tiempo\\_a√±os}_{ij} + u_{0i} + u_{1i} \\times \\text{tiempo\\_a√±os}_{ij} + \\varepsilon_{ij}\n",
    "\\]\n",
    "\n",
    "Donde:\n",
    "- \\( \\beta_0, \\beta_1 \\) ‚Üí efectos fijos (intercepto y pendiente media poblacional).  \n",
    "- \\( u_{0i}, u_{1i} \\) ‚Üí efectos aleatorios por paciente (variaci√≥n interindividual).  \n",
    "- \\( \\varepsilon_{ij} \\) ‚Üí error residual intraindividual.\n",
    "\n",
    "El modelo se implementa as√≠:\n",
    "\n",
    "```python\n",
    "modelo = smf.mixedlm(\n",
    "    formula=\"MDS_UPDRS_III ~ tiempo_a√±os\",\n",
    "    data=df_mlm,\n",
    "    groups=df_mlm[\"num.consec\"],\n",
    "    re_formula=\"~tiempo_a√±os\"  # pendiente aleatoria por paciente\n",
    ").fit(reml=False, method=\"lbfgs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtifzbhWq1vh"
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "#  MIXED-LM ROBUSTO: PENDIENTE INDIVIDUAL (MDS-UPDRS III)\n",
    "# --------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "\n",
    "# 0. Copia de trabajo\n",
    "df_mlm = df_clean.copy()\n",
    "\n",
    "# 1. Conversi√≥n de tipos y descarte de NaN\n",
    "cols_req = [\"num.consec\", \"MDS_UPDRS_III\", \"tiempo_a√±os\"]\n",
    "df_mlm = df_mlm[cols_req].dropna()\n",
    "\n",
    "df_mlm[\"num.consec\"]      = df_mlm[\"num.consec\"].astype(\"category\")\n",
    "df_mlm[\"MDS_UPDRS_III\"]   = pd.to_numeric(df_mlm[\"MDS_UPDRS_III\"], errors=\"coerce\")\n",
    "df_mlm[\"tiempo_a√±os\"]     = pd.to_numeric(df_mlm[\"tiempo_a√±os\"],  errors=\"coerce\")\n",
    "df_mlm = df_mlm.dropna()\n",
    "\n",
    "# 2. Mantener solo pacientes con ‚â•2 visitas *y* ‚â•2 tiempos distintos\n",
    "def good_group(x):\n",
    "    return (len(x) >= 2) and (x[\"tiempo_a√±os\"].nunique() >= 2)\n",
    "\n",
    "df_mlm = df_mlm.groupby(\"num.consec\").filter(good_group)\n",
    "\n",
    "# 3. Resetear √≠ndice para evitar huecos\n",
    "df_mlm = df_mlm.reset_index(drop=True)\n",
    "\n",
    "print(\"Observaciones:\", len(df_mlm),\n",
    "      \"| Pacientes:\", df_mlm[\"num.consec\"].nunique())\n",
    "\n",
    "# 4. Modelo lineal mixto (intercepto + pendiente aleatoria)\n",
    "modelo = smf.mixedlm(\n",
    "    formula=\"MDS_UPDRS_III ~ tiempo_a√±os\",\n",
    "    data=df_mlm,\n",
    "    groups=df_mlm[\"num.consec\"],\n",
    "    re_formula=\"~tiempo_a√±os\"        #  ‚Üê incluye random-slope\n",
    ").fit(reml=False, method=\"lbfgs\")     # LBFGS: m√°s estable que default Newton\n",
    "\n",
    "print(modelo.summary())\n",
    "\n",
    "# 5. Extraer pendientes individuales (coef. de tiempo_a√±os)\n",
    "pend_slopes = {\n",
    "    k: v[\"tiempo_a√±os\"] for k, v in modelo.random_effects.items()\n",
    "}\n",
    "\n",
    "df_slopes = (pd.Series(pend_slopes, name=\"pendiente_III\")\n",
    "               .reset_index()\n",
    "               .rename(columns={\"index\": \"num.consec\"}))\n",
    "\n",
    "display(df_slopes.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cr√©ditos\n",
    "\n",
    "Desarrollado por:  \n",
    "**Laboratorio Cl√≠nico de Enfermedades Neurodegenerativas (LCEN)**  \n",
    "Instituto Nacional de Neurolog√≠a y Neurocirug√≠a ‚ÄúManuel Velasco Su√°rez‚Äù (INNN)  \n",
    "Ciudad de M√©xico, M√©xico  \n",
    "\n",
    "Colaboradores:  \n",
    "- Dr. Amin Cervantes-Arriaga  \n",
    "- Dra. Mayela Rodr√≠guez-Violante  \n",
    "- Equipo ReMePARK ‚Äì LCEN-INNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licencia\n",
    "\n",
    "Este trabajo se distribuye bajo la licencia [MIT](./LICENSE).  \n",
    "Puedes usarlo, modificarlo y compartirlo citando la fuente original.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1zoJzERq3qWjzbzN2E4e9HAVC4DEvvOu3",
     "timestamp": 1748653636168
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
